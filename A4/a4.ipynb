{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source credit: https://huggingface.co/datasets/legacy-datasets/wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bidhan\\anaconda3\\envs\\ait\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Bidhan\\anaconda3\\envs\\ait\\Lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 6458670\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikipedia\", \"20220301.en\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '12',\n",
       " 'url': 'https://en.wikipedia.org/wiki/Anarchism',\n",
       " 'title': 'Anarchism',\n",
       " 'text': 'Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian Marxism as the libertarian wing (libertarian socialism) of the socialist movement, and has a strong historical association with anti-capitalism and socialism.\\n\\nHumans lived in societies without formal hierarchies long before the establishment of formal states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose. Although traces of anarchist thought are found throughout history, modern anarchism emerged from the Enlightenment. During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers\\' struggles for emancipation. Various anarchist schools of thought formed during this period. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more.\\n\\nAnarchism employs a diversity of tactics in order to meet its ideal ends which can be broadly separated into revolutionary and evolutionary tactics; there is significant overlap between the two, which are merely descriptive. Revolutionary tactics aim to bring down authority and state, having taken a violent turn in the past, while evolutionary tactics aim to prefigure what an anarchist society would be like. Anarchist thought, criticism, and praxis have played a part in diverse areas of human society. Criticism of anarchism include claims that it is internally inconsistent, violent, or utopian.\\n\\nEtymology, terminology, and definition \\n\\nThe etymological origin of anarchism is from the Ancient Greek anarkhia, meaning \"without a ruler\", composed of the prefix an- (\"without\") and the word arkhos (\"leader\" or \"ruler\"). The suffix -ism denotes the ideological current that favours anarchy. Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder. Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists. Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.\\n\\nThe first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century. Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.\\n\\nWhile the term libertarian has been largely synonymous with anarchism, its meaning has more recently diluted with wider adoption from ideologically disparate groups, including both the New Left and libertarian Marxists, who do not associate themselves with authoritarian socialists or a vanguard party, and extreme cultural liberals, who are primarily concerned with civil liberties. Additionally, some anarchists use libertarian socialist to avoid anarchism\\'s negative connotations and emphasise its connections with socialism. Anarchism is broadly used to describe the anti-authoritarian wing of the socialist movement. Anarchism is contrasted to socialist forms which are state-oriented or from above. Scholars of anarchism generally highlight anarchism\\'s socialist credentials and criticise attempts at creating dichotomies between the two. Some scholars describe anarchism as having many influences from liberalism, and being both liberals and socialists but more so, while most scholars reject anarcho-capitalism as a misunderstanding of anarchist principles.\\n\\nWhile opposition to the state is central to anarchist thought, defining anarchism is not an easy task for scholars, as there is a lot of discussion among scholars and anarchists on the matter, and various currents perceive anarchism slightly differently. Major definitional elements include the will for a non-coercive society, the rejection of the state apparatus, the belief that human nature allows humans to exist in or progress toward such a non-coercive society, and a suggestion on how to act to pursue the ideal of anarchy.\\n\\nHistory\\n\\nPre-modern era \\n\\nBefore the establishment of towns and cities, an established authority did not exist. It was after the creation of institutions of authority that anarchistic ideas espoused as a reaction. The most notable precursors to anarchism in the ancient world were in China and Greece. In China, philosophical anarchism (the discussion on the legitimacy of the state) was delineated by Taoist philosophers Zhuang Zhou and Laozi. Alongside Stoicism, Taoism has been said to have had \"significant anticipations\" of anarchism.\\n \\nAnarchic attitudes were also articulated by tragedians and philosophers in Greece. Aeschylus and Sophocles used the myth of Antigone to illustrate the conflict between rules set by the state and personal autonomy. Socrates questioned Athenian authorities constantly and insisted on the right of individual freedom of conscience. Cynics dismissed human law (nomos) and associated authorities while trying to live according to nature (physis). Stoics were supportive of a society based on unofficial and friendly relations among its citizens without the presence of a state.\\n\\nIn medieval Europe, there was no anarchistic activity except some ascetic religious movements. These, and other Muslim movements, later gave birth to religious anarchism. In the Sasanian Empire, Mazdak called for an egalitarian society and the abolition of monarchy, only to be soon executed by Emperor Kavad I.\\n\\nIn Basra, religious sects preached against the state. In Europe, various sects developed anti-state and libertarian tendencies. Renewed interest in antiquity during the Renaissance and in private judgment during the Reformation restored elements of anti-authoritarian secularism, particularly in France. Enlightenment challenges to intellectual authority (secular and religious) and the revolutions of the 1790s and 1848 all spurred the ideological development of what became the era of classical anarchism.\\n\\nModern era \\nDuring the French Revolution, partisan groups such as the Enragés and the  saw a turning point in the fermentation of anti-state and federalist sentiments. The first anarchist currents developed throughout the 18th century as William Godwin espoused philosophical anarchism in England, morally delegitimising the state, Max Stirner\\'s thinking paved the way to individualism and Pierre-Joseph Proudhon\\'s theory of mutualism found fertile soil in France. By the late 1870s, various anarchist schools of thought had become well-defined and a wave of then unprecedented globalisation occurred from 1880 to 1914. This era of classical anarchism lasted until the end of the Spanish Civil War and is considered the golden age of anarchism.\\n\\nDrawing from mutualism, Mikhail Bakunin founded collectivist anarchism and entered the International Workingmen\\'s Association, a class worker union later known as the First International that formed in 1864 to unite diverse revolutionary currents. The International became a significant political force, with Karl Marx being a leading figure and a member of its General Council. Bakunin\\'s faction (the Jura Federation) and Proudhon\\'s followers (the mutualists) opposed state socialism, advocating political abstentionism and small property holdings. After bitter disputes, the Bakuninists were expelled from the International by the Marxists at the 1872 Hague Congress. Anarchists were treated similarly in the Second International, being ultimately expelled in 1896. Bakunin famously predicted that if revolutionaries gained power by Marx\\'s terms, they would end up the new tyrants of workers. In response to their expulsion from the First International, anarchists formed the St. Imier International. Under the influence of Peter Kropotkin, a Russian philosopher and scientist, anarcho-communism overlapped with collectivism. Anarcho-communists, who drew inspiration from the 1871 Paris Commune, advocated for free federation and for the distribution of goods according to one\\'s needs.\\n\\nAt the turn of the century, anarchism had spread all over the world. It was a notable feature of the international syndicalism movement. In China, small groups of students imported the humanistic pro-science version of anarcho-communism. Tokyo was a hotspot for rebellious youth from countries of the far east, travelling to the Japanese capital to study. In Latin America, Argentina was a stronghold for anarcho-syndicalism, where it became the most prominent left-wing ideology. During this time, a minority of anarchists adopted tactics of revolutionary political violence. This strategy became known as propaganda of the deed. The dismemberment of the French socialist movement into many groups and the execution and exile of many Communards to penal colonies following the suppression of the Paris Commune favoured individualist political expression and acts. Even though many anarchists distanced themselves from these terrorist acts, infamy came upon the movement and attempts were made to exclude them from American immigration, including the Immigration Act of 1903, also called the Anarchist Exclusion Act. Illegalism was another strategy which some anarchists adopted during this period.\\n\\nDespite concerns, anarchists enthusiastically participated in the Russian Revolution in opposition to the White movement; however, they met harsh suppression after the Bolshevik government was stabilised. Several anarchists from Petrograd and Moscow fled to Ukraine, notably leading to the Kronstadt rebellion and Nestor Makhno\\'s struggle in the Free Territory. With the anarchists being crushed in Russia, two new antithetical currents emerged, namely platformism and synthesis anarchism. The former sought to create a coherent group that would push for revolution while the latter were against anything that would resemble a political party. Seeing the victories of the Bolsheviks in the October Revolution and the resulting Russian Civil War, many workers and activists turned to communist parties which grew at the expense of anarchism and other socialist movements. In France and the United States, members of major syndicalist movements such as the General Confederation of Labour and the Industrial Workers of the World left their organisations and joined the Communist International.\\n\\nIn the Spanish Civil War of 1936, anarchists and syndicalists (CNT and FAI) once again allied themselves with various currents of leftists. A long tradition of Spanish anarchism led to anarchists playing a pivotal role in the war. In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain, where they collectivised the land. The Soviet Union provided some limited assistance at the beginning of the war, but the result was a bitter fight among communists and anarchists at a series of events named May Days as Joseph Stalin tried to seize control of the Republicans.\\n\\nPost-war era \\n\\nAt the end of World War II, the anarchist movement was severely weakened. The 1960s witnessed a revival of anarchism, likely caused by a perceived failure of Marxism–Leninism and tensions built by the Cold War. During this time, anarchism found a presence in other movements critical towards both capitalism and the state such as the anti-nuclear, environmental, and peace movements, the counterculture of the 1960s, and the New Left. It also saw a transition from its previous revolutionary nature to provocative anti-capitalist reformism. Anarchism became associated with punk subculture as exemplified by bands such as Crass and the Sex Pistols. The established feminist tendencies of anarcha-feminism returned with vigour during the second wave of feminism. Black anarchism began to take form at this time and influenced anarchism\\'s move from a Eurocentric demographic. This coincided with its failure to gain traction in Northern Europe and its unprecedented height in Latin America.\\n\\nAround the turn of the 21st century, anarchism grew in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements. Anarchists became known for their involvement in protests against the World Trade Organization (WTO), the Group of Eight and the World Economic Forum. During the protests, ad hoc leaderless anonymous cadres known as black blocs engaged in rioting, property destruction and violent confrontations with the police. Other organisational tactics pioneered in this time include affinity groups, security culture and the use of decentralised technologies such as the Internet. A significant event of this period was the confrontations at the 1999 Seattle WTO conference. Anarchist ideas have been influential in the development of the Zapatistas in Mexico and the Democratic Federation of Northern Syria, more commonly known as Rojava, a de facto autonomous region in northern Syria.\\n\\nThought \\n\\nAnarchist schools of thought have been generally grouped into two main historical traditions, social anarchism and individualist anarchism, owing to their different origins, values and evolution. The individualist current emphasises negative liberty in opposing restraints upon the free individual, while the social current emphasises positive liberty in aiming to achieve the free potential of society through equality and social ownership. In a chronological sense, anarchism can be segmented by the classical currents of the late 19th century and the post-classical currents (anarcha-feminism, green anarchism, and post-anarchism) developed thereafter.\\n\\nBeyond the specific factions of anarchist movements which constitute political anarchism lies philosophical anarchism which holds that the state lacks moral legitimacy, without necessarily accepting the imperative of revolution to eliminate it. A component especially of individualist anarchism, philosophical anarchism may tolerate the existence of a minimal state but claims that citizens have no moral obligation to obey government when it conflicts with individual autonomy. Anarchism pays significant attention to moral arguments since ethics have a central role in anarchist philosophy. Anarchism\\'s emphasis on anti-capitalism, egalitarianism, and for the extension of community and individuality sets it apart from anarcho-capitalism and other types of economic libertarianism.\\n\\nAnarchism is usually placed on the far-left of the political spectrum. Much of its economics and legal philosophy reflect anti-authoritarian, anti-statist, libertarian, and radical interpretations of left-wing and socialist politics such as collectivism, communism, individualism, mutualism, and syndicalism, among other libertarian socialist economic theories. As anarchism does not offer a fixed body of doctrine from a single particular worldview, many anarchist types and traditions exist and varieties of anarchy diverge widely. One reaction against sectarianism within the anarchist milieu was anarchism without adjectives, a call for toleration and unity among anarchists first adopted by Fernando Tarrida del Mármol in 1889 in response to the bitter debates of anarchist theory at the time. Belief in political nihilism has been espoused by anarchists. Despite separation, the various anarchist schools of thought are not seen as distinct entities but rather as tendencies that intermingle and are connected through a set of uniform principles such as individual and local autonomy, mutual aid, network organisation, communal democracy, justified authority and decentralisation.\\n\\nClassical \\n\\nInceptive currents among classical anarchist currents were mutualism and individualism. They were followed by the major currents of social anarchism (collectivist, communist and syndicalist). They differ on organisational and economic aspects of their ideal society.\\n\\nMutualism is an 18th-century economic theory that was developed into anarchist theory by Pierre-Joseph Proudhon. Its aims include reciprocity, free association, voluntary contract, federation and monetary reform of both credit and currency that would be regulated by a bank of the people. Mutualism has been retrospectively characterised as ideologically situated between individualist and collectivist forms of anarchism. In What Is Property? (1840), Proudhon first characterised his goal as a \"third form of society, the synthesis of communism and property.\" Collectivist anarchism is a revolutionary socialist form of anarchism commonly associated with Mikhail Bakunin. Collectivist anarchists advocate collective ownership of the means of production which is theorised to be achieved through violent revolution and that workers be paid according to time worked, rather than goods being distributed according to need as in communism. Collectivist anarchism arose alongside Marxism but rejected the dictatorship of the proletariat despite the stated Marxist goal of a collectivist stateless society.\\n\\nAnarcho-communism is a theory of anarchism that advocates a communist society with common ownership of the means of production, direct democracy and a horizontal network of voluntary associations, workers\\' councils and worker cooperatives, with production and consumption based on the guiding principle \"From each according to his ability, to each according to his need.\" Anarcho-communism developed from radical socialist currents after the French Revolution but was first formulated as such in the Italian section of the First International. It was later expanded upon in the theoretical work of Peter Kropotkin, whose specific style would go onto become the dominating view of anarchists by the late 19th century. Anarcho-syndicalism is a branch of anarchism that views labour syndicates as a potential force for revolutionary social change, replacing capitalism and the state with a new society democratically self-managed by workers. The basic principles of anarcho-syndicalism are direct action, workers\\' solidarity and workers\\' self-management.\\n\\nIndividualist anarchism is a set of several traditions of thought within the anarchist movement that emphasise the individual and their will over any kinds of external determinants. Early influences on individualist forms of anarchism include William Godwin, Max Stirner, and Henry David Thoreau. Through many countries, individualist anarchism attracted a small yet diverse following of Bohemian artists and intellectuals as well as young anarchist outlaws in what became known as illegalism and individual reclamation.\\n\\nPost-classical and contemporary \\n\\nAnarchist principles undergird contemporary radical social movements of the left. Interest in the anarchist movement developed alongside momentum in the anti-globalisation movement, whose leading activist networks were anarchist in orientation. As the movement shaped 21st century radicalism, wider embrace of anarchist principles signaled a revival of interest. Anarchism has continued to generate many philosophies and movements, at times eclectic, drawing upon various sources and combining disparate concepts to create new philosophical approaches. The anti-capitalist tradition of classical anarchism has remained prominent within contemporary currents.\\n\\nContemporary news coverage which emphasizes black bloc demonstrations has reinforced anarchism\\'s historical association with chaos and violence. Its publicity has also led more scholars in fields such as anthropology and history to engage with the anarchist movement, although contemporary anarchism favours actions over academic theory. Various anarchist groups, tendencies, and schools of thought exist today, making it difficult to describe the contemporary anarchist movement. While theorists and activists have established \"relatively stable constellations of anarchist principles\", there is no consensus on which principles are core and commentators describe multiple anarchisms, rather than a singular anarchism, in which common principles are shared between schools of anarchism while each group prioritizes those principles differently. Gender equality can be a common principle, although it ranks as a higher priority to anarcha-feminists than anarcho-communists.\\n\\nAnarchists are generally committed against coercive authority in all forms, namely \"all centralized and hierarchical forms of government (e.g., monarchy, representative democracy, state socialism, etc.), economic class systems (e.g., capitalism, Bolshevism, feudalism, slavery, etc.), autocratic religions (e.g., fundamentalist Islam, Roman Catholicism, etc.), patriarchy, heterosexism, white supremacy, and imperialism.\" Anarchist schools disagree on the methods by which these forms should be opposed. The principle of equal liberty is closer to anarchist political ethics in that it transcends both the liberal and socialist traditions. This entails that liberty and equality cannot be implemented within the state, resulting in the questioning of all forms of domination and hierarchy.\\n\\nTactics \\nAnarchists\\' tactics take various forms but in general serve two major goals, namely to first oppose the Establishment and secondly to promote anarchist ethics and reflect an anarchist vision of society, illustrating the unity of means and ends. A broad categorisation can be made between aims to destroy oppressive states and institutions by revolutionary means on one hand and aims to change society through evolutionary means on the other. Evolutionary tactics embrace nonviolence, reject violence and take a gradual approach to anarchist aims, although there is significant overlap between the two.\\n\\nAnarchist tactics have shifted during the course of the last century. Anarchists during the early 20th century focused more on strikes and militancy while contemporary anarchists use a broader array of approaches.\\n\\nClassical era tactics \\n\\nDuring the classical era, anarchists had a militant tendency. Not only did they confront state armed forces, as in Spain and Ukraine, but some of them also employed terrorism as propaganda of the deed. Assassination attempts were carried out against heads of state, some of which were successful. Anarchists also took part in revolutions. Many anarchists, especially the Galleanists, believed that these attempts would be the impetus for a revolution against capitalism and the state. Many of these attacks were done by individual assailants and the majority took place in the late 1870s, the early 1880s and the 1890s, with some still occurring in the early 1900s. Their decrease in prevalence was the result of further judicial power and targeting and cataloging by state institutions.\\n\\nAnarchist perspectives towards violence have always been controversial. Anarcho-pacifists advocate for non-violence means to achieve their stateless, nonviolent ends. Other anarchist groups advocate direct action, a tactic which can include acts of sabotage or terrorism. This attitude was quite prominent a century ago when seeing the state as a tyrant and some anarchists believing that they had every right to oppose its oppression by any means possible. Emma Goldman and Errico Malatesta, who were proponents of limited use of violence, stated that violence is merely a reaction to state violence as a necessary evil.\\n\\nAnarchists took an active role in strike actions, although they tended to be antipathetic to formal syndicalism, seeing it as reformist. They saw it as a part of the movement which sought to overthrow the state and capitalism. Anarchists also reinforced their propaganda within the arts, some of whom practiced naturism and nudism. Those anarchists also built communities which were based on friendship and were involved in the news media.\\n\\nRevolutionary tactics \\n\\nIn the current era, Italian anarchist Alfredo Bonanno, a proponent of insurrectionary anarchism, has reinstated the debate on violence by rejecting the nonviolence tactic adopted since the late 19th century by Kropotkin and other prominent anarchists afterwards. Both Bonanno and the French group The Invisible Committee advocate for small, informal affiliation groups, where each member is responsible for their own actions but works together to bring down oppression utilizing sabotage and other violent means against state, capitalism, and other enemies. Members of The Invisible Committee were arrested in 2008 on various charges, terrorism included.\\n\\nOverall, contemporary anarchists are much less violent and militant than their ideological ancestors. They mostly engage in confronting the police during demonstrations and riots, especially in countries such as Canada, Greece, and Mexico. Militant black bloc protest groups are known for clashing with the police; however, anarchists not only clash with state operators, they also engage in the struggle against fascists and racists, taking anti-fascist action and mobilizing to prevent hate rallies from happening.\\n\\nEvolutionary tactics \\nAnarchists commonly employ direct action. This can take the form of disrupting and protesting against unjust hierarchy, or the form of self-managing their lives through the creation of counter-institutions such as communes and non-hierarchical collectives. Decision-making is often handled in an anti-authoritarian way, with everyone having equal say in each decision, an approach known as horizontalism. Contemporary-era anarchists have been engaging with various grassroots movements that are more or less based on horizontalism, although not explicitly anarchist, respecting personal autonomy and participating in mass activism such as strikes and demonstrations. In contrast with the big-A anarchism of the classical era, the newly coined term small-a anarchism signals their tendency not to base their thoughts and actions on classical-era anarchism or to refer to classical anarchists such as Peter Kropotkin and Pierre-Joseph Proudhon to justify their opinions. Those anarchists would rather base their thought and praxis on their own experience which they will later theorize.\\n\\nThe decision-making process of small anarchist affinity groups plays a significant tactical role. Anarchists have employed various methods in order to build a rough consensus among members of their group without the need of a leader or a leading group. One way is for an individual from the group to play the role of facilitator to help achieve a consensus without taking part in the discussion themselves or promoting a specific point. Minorities usually accept rough consensus, except when they feel the proposal contradicts anarchist ethics, goals and values. Anarchists usually form small groups (5–20 individuals) to enhance autonomy and friendships among their members. These kinds of groups more often than not interconnect with each other, forming larger networks. Anarchists still support and participate in strikes, especially wildcat strikes as these are leaderless strikes not organised centrally by a syndicate.\\n\\nAs in the past, newspapers and journals are used, and anarchists have gone online in the World Wide Web to spread their message. Anarchists have found it easier to create websites because of distributional and other difficulties, hosting electronic libraries and other portals. Anarchists were also involved in developing various software that are available for free. The way these hacktivists work to develop and distribute resembles the anarchist ideals, especially when it comes to preserving users\\' privacy from state surveillance.\\n\\nAnarchists organize themselves to squat and reclaim public spaces. During important events such as protests and when spaces are being occupied, they are often called Temporary Autonomous Zones (TAZ), spaces where art, poetry, and surrealism are blended to display the anarchist ideal. As seen by anarchists, squatting is a way to regain urban space from the capitalist market, serving pragmatical needs and also being an exemplary direct action. Acquiring space enables anarchists to experiment with their ideas and build social bonds. Adding up these tactics while having in mind that not all anarchists share the same attitudes towards them, along with various forms of protesting at highly symbolic events, make up a carnivalesque atmosphere that is part of contemporary anarchist vividity.\\n\\nKey issues \\n\\nAs anarchism is a philosophy that embodies many diverse attitudes, tendencies, and schools of thought; disagreement over questions of values, ideology, and tactics is common. Its diversity has led to widely different uses of identical terms among different anarchist traditions which has created a number of definitional concerns in anarchist theory. The compatibility of capitalism, nationalism, and religion with anarchism is widely disputed, and anarchism enjoys complex relationships with ideologies such as communism, collectivism, Marxism, and trade unionism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest, veganism, or any number of alternative ethical doctrines. Phenomena such as civilisation, technology (e.g. within anarcho-primitivism), and the democratic process may be sharply criticised within some anarchist tendencies and simultaneously lauded in others.\\n\\nGender, sexuality, and free love \\n\\nAs gender and sexuality carry along them dynamics of hierarchy, many anarchists address, analyse, and oppose the suppression of one\\'s autonomy imposed by gender roles.\\n\\nSexuality was not often discussed by classical anarchists but the few that did felt that an anarchist society would lead to sexuality naturally developing. Sexual violence was a concern for anarchists such as Benjamin Tucker, who opposed age of consent laws, believing they would benefit predatory men. A historical current that arose and flourished during 1890 and 1920 within anarchism was free love. In contemporary anarchism, this current survives as a tendency to support polyamory and queer anarchism. Free love advocates were against marriage, which they saw as a way of men imposing authority over women, largely because marriage law greatly favoured the power of men. The notion of free love was much broader and included a critique of the established order that limited women\\'s sexual freedom and pleasure. Those free love movements contributed to the establishment of communal houses, where large groups of travelers, anarchists and other activists slept in beds together. Free love had roots both in Europe and the United States; however, some anarchists struggled with the jealousy that arose from free love. Anarchist feminists were advocates of free love, against marriage, and pro-choice (utilising a contemporary term), and had a similar agenda. Anarchist and non-anarchist feminists differed on suffrage but were supportive of one another.\\n\\nDuring the second half of the 20th century, anarchism intermingled with the second wave of feminism, radicalising some currents of the feminist movement and being influenced as well. By the latest decades of the 20th century, anarchists and feminists were advocating for the rights and autonomy of women, gays, queers and other marginalised groups, with some feminist thinkers suggesting a fusion of the two currents. With the third wave of feminism, sexual identity and compulsory heterosexuality became a subject of study for anarchists, yielding a post-structuralist critique of sexual normality. Some anarchists distanced themselves from this line of thinking, suggesting that it leaned towards an individualism that was dropping the cause of social liberation.\\n\\nAnarchism and education \\n\\nThe interest of anarchists in education stretches back to the first emergence of classical anarchism. Anarchists consider proper education, one which sets the foundations of the future autonomy of the individual and the society, to be an act of mutual aid. Anarchist writers such as William Godwin (Political Justice) and Max Stirner (\"The False Principle of Our Education\") attacked both state education and private education as another means by which the ruling class replicate their privileges.\\n\\nIn 1901, Catalan anarchist and free thinker Francisco Ferrer established the Escuela Moderna in Barcelona as an opposition to the established education system which was dictated largely by the Catholic Church. Ferrer\\'s approach was secular, rejecting both state and church involvement in the educational process whilst giving pupils large amounts of autonomy in planning their work and attendance. Ferrer aimed to educate the working class and explicitly sought to foster class consciousness among students. The school closed after constant harassment by the state and Ferrer was later arrested. Nonetheless, his ideas formed the inspiration for a series of modern schools around the world. Christian anarchist Leo Tolstoy, who published the essay Education and Culture, also established a similar school with its founding principle being that \"for education to be effective it had to be free.\" In a similar token, A. S. Neill founded what became the Summerhill School in 1921, also declaring being free from coercion.\\n\\nAnarchist education is based largely on the idea that a child\\'s right to develop freely and without manipulation ought to be respected and that rationality would lead children to morally good conclusions; however, there has been little consensus among anarchist figures as to what constitutes manipulation. Ferrer believed that moral indoctrination was necessary and explicitly taught pupils that equality, liberty and social justice were not possible under capitalism, along with other critiques of government and nationalism.\\n\\nLate 20th century and contemporary anarchist writers (Paul Goodman, Herbert Read, and Colin Ward) intensified and expanded the anarchist critique of state education, largely focusing on the need for a system that focuses on children\\'s creativity rather than on their ability to attain a career or participate in consumerism as part of a consumer society. Contemporary anarchists such as Ward claim that state education serves to perpetuate socioeconomic inequality.\\n\\nWhile few anarchist education institutions have survived to the modern-day, major tenets of anarchist schools, among them respect for child autonomy and relying on reasoning rather than indoctrination as a teaching method, have spread among mainstream educational institutions. Judith Suissa names three schools as explicitly anarchists schools, namely the Free Skool Santa Cruz in the United States which is part of a wider American-Canadian network of schools, the Self-Managed Learning College in Brighton, England, and the Paideia School in Spain.\\n\\nAnarchism and the state \\n\\nObjection to the state and its institutions is a sine qua non of anarchism. Anarchists consider the state as a tool of domination and believe it to be illegitimate regardless of its political tendencies. Instead of people being able to control the aspects of their life, major decisions are taken by a small elite. Authority ultimately rests solely on power, regardless of whether that power is open or transparent, as it still has the ability to coerce people. Another anarchist argument against states is that the people constituting a government, even the most altruistic among officials, will unavoidably seek to gain more power, leading to corruption. Anarchists consider the idea that the state is the collective will of the people to be an unachievable fiction due to the fact that the ruling class is distinct from the rest of society.\\n\\nSpecific anarchist attitudes towards the state vary. Robert Paul Wolff believed that the tension between authority and autonomy would mean the state could never be legitimate. Bakunin saw the state as meaning \"coercion, domination by means of coercion, camouflaged if possible but unceremonious and overt if need be.\" A. John Simmons and Leslie Green, who leaned toward philosophical anarchism, believed that the state could be legitimate if it is governed by consensus, although they saw this as highly unlikely. Beliefs on how to abolish the state also differ.\\n\\nAnarchism and the arts \\n\\nThe connection between anarchism and art was quite profound during the classical era of anarchism, especially among artistic currents that were developing during that era such as futurists, surrealists and others. In literature, anarchism was mostly associated with the New Apocalyptics and the neo-romanticism movement. In music, anarchism has been associated with music scenes such as punk. Anarchists such as Leo Tolstoy and Herbert Read stated that the border between the artist and the non-artist, what separates art from a daily act, is a construct produced by the alienation caused by capitalism and it prevents humans from living a joyful life.\\n\\nOther anarchists advocated for or used art as a means to achieve anarchist ends. In his book Breaking the Spell: A History of Anarchist Filmmakers, Videotape Guerrillas, and Digital Ninjas, Chris Robé claims that \"anarchist-inflected practices have increasingly structured movement-based video activism.\" Throughout the 20th century, many prominent anarchists (Peter Kropotkin, Emma Goldman, Gustav Landauer and Camillo Berneri) and publications such as Anarchy wrote about matters pertaining to the arts.\\n\\nThree overlapping properties made art useful to anarchists. It could depict a critique of existing society and hierarchies, serve as a prefigurative tool to reflect the anarchist ideal society and even turn into a means of direct action such as in protests. As it appeals to both emotion and reason, art could appeal to the whole human and have a powerful effect. The 19th-century neo-impressionist movement had an ecological aesthetic and offered an example of an anarchist perception of the road towards socialism. In Les chataigniers a Osny by anarchist painter Camille Pissarro, the blending of aesthetic and social harmony is prefiguring an ideal anarchistic agrarian community.\\n\\nAnalysis \\nThe most common critique of anarchism is that humans cannot self-govern and so a state is necessary for human survival. Philosopher Bertrand Russell supported this critique, stating that \"[p]eace and war, tariffs, regulations of sanitary conditions and the sale of noxious drugs, the preservation of a just system of distribution: these, among others, are functions which could hardly be performed in a community in which there was no central government.\" Another common criticism of anarchism is that it fits a world of isolation in which only the small enough entities can be self-governing; a response would be that major anarchist thinkers advocated anarchist federalism.\\n\\nPhilosophy lecturer Andrew G. Fiala composed a list of common arguments against anarchism which includes critiques such as that anarchism is innately related to violence and destruction, not only in the pragmatic world, such as at protests, but in the world of ethics as well. Secondly, anarchism is evaluated as unfeasible or utopian since the state cannot be defeated practically. This line of arguments most often calls for political action within the system to reform it. The third argument is that anarchism is self-contradictory. While it advocates for no-one to archiei, if accepted by the many, then anarchism would turn into the ruling political theory. In this line of criticism also comes the self-contradiction that anarchism calls for collective action whilst endorsing the autonomy of the individual, hence no collective action can be taken. Lastly, Fiala mentions a critique towards philosophical anarchism of being ineffective (all talk and thoughts) and in the meantime capitalism and bourgeois class remains strong.\\n\\nPhilosophical anarchism has met the criticism of members of academia following the release of pro-anarchist books such as A. John Simmons\\' Moral Principles and Political Obligations. Law professor William A. Edmundson authored an essay to argue against three major philosophical anarchist principles which he finds fallacious. Edmundson says that while the individual does not owe the state a duty of obedience, this does not imply that anarchism is the inevitable conclusion and the state is still morally legitimate. In The Problem of Political Authority, Michael Huemer defends philosophical anarchism, claiming that \"political authority is a moral illusion.\"\\n\\nOne of the earliest criticisms is that anarchism defies and fails to understand the biological inclination to authority. Joseph Raz states that the acceptance of authority implies the belief that following their instructions will afford more success. Raz believes that this argument is true in following both authorities\\' successful and mistaken instruction. Anarchists reject this criticism because challenging or disobeying authority does not entail the disappearance of its advantages by acknowledging authority such as doctors or lawyers as reliable, nor does it involve a complete surrender of independent judgment. Anarchist perception of human nature, rejection of the state, and commitment to social revolution has been criticised by academics as naive, overly simplistic, and unrealistic, respectively. Classical anarchism has been criticised for relying too heavily on the belief that the abolition of the state will lead to human cooperation prospering.\\n\\nFriedrich Engels, considered to be one of the principal founders of Marxism, criticised anarchism\\'s anti-authoritarianism as inherently counter-revolutionary because in his view a revolution is by itself authoritarian. Academic John Molyneux writes in his book Anarchism: A Marxist Criticism that \"anarchism cannot win\", believing that it lacks the ability to properly implement its ideas. The Marxist criticism of anarchism is that it has a utopian character because all individuals should have anarchist views and values. According to the Marxist view, that a social idea would follow directly from this human ideal and out of the free will of every individual formed its essence. Marxists state that this contradiction was responsible for their inability to act. In the anarchist vision, the conflict between liberty and equality was resolved through coexistence and intertwining.\\n\\nSee also \\n\\n Anarchism by country\\n Governance without government\\n List of anarchist political ideologies\\n List of books about anarchism\\n\\nReferences\\n\\nCitations\\n\\nNotes\\n\\nSources\\n\\nPrimary sources\\n\\nSecondary sources\\n\\nTertiary sources\\n\\nFurther reading \\n \\n  Criticism of philosophical anarchism.\\n \\n  A defence of philosophical anarchism, stating that \"both kinds of \\'anarchism\\' [i.e. philosophical and political anarchism] are philosophical and political claims.\" (p.\\xa0137)\\n  Anarchistic popular fiction novel.\\n \\n \\n \\n  An argument for philosophical anarchism.\\n\\nExternal links \\n Anarchy Archives. Anarchy Archives is an online research center on the history and theory of anarchism.\\n\\n \\nAnti-capitalism\\nAnti-fascism\\nEconomic ideologies\\nLeft-wing politics\\nLibertarian socialism\\nLibertarianism\\nPolitical culture\\nPolitical movements\\nPolitical ideologies\\nSocial theories\\nSocialism\\nFar-left politics'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0] # check the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random numnber generator\n",
    "rand = default_rng(SEED)\n",
    "\n",
    "# random index from the dataset\n",
    "# reducing the size of the dataset to 100k\n",
    "random_index = rand.choice(len(dataset['train']), 100000, replace=False)\n",
    "\n",
    "dataset['train'] = dataset['train'].filter(lambda data, index: index in random_index, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset # after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing unwanted columns\n",
    "dataset = dataset.remove_columns(['id', 'url', 'title'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaxarchus (; ; ) was a Greek philosopher of the school of Democritus. Together with Pyrrho, he accompanied Alexander the Great into Asia. The reports of his philosophical views suggest that he was a forerunner of Pyrrhonism. Aelian writes that he was called Eudaemonicus or \"Happy Man\" ().  Life   Anaxarchus was born at Abdera in Thrace. He was the companion and friend of Alexander the Great in his Asiatic campaigns. According to Diogenes Laërtius, in response to Alexander\\'s claim to have been the son of Zeus-Ammon, Anaxarchus pointed to his bleeding wound and remarked, \"See the blood of a mortal, not ichor, such as flows from the veins of the immortal gods.\" Aelian, writes that Anaxarchus laughed at Alexander for making himself a god and said, \"The hopes of our god are in a porringer of broth\", when the physician prescribed a broth to Alexander.  Plutarch tells a story that at Bactra, in 327\\xa0BC in a debate with Callisthenes, he advised all to worship Alexander as a god even during his lifetime, as they would surely do it after he died.  When Alexander was trying to show that he is divine so that the Macedonians would perform proskynesis to him, Anaxarchus said that Alexander could \"more justly be considered a god than Dionysus or Heracles\", as Dionysus was Theban while Heracles was Alexander\\'s non-Macedonian ancestor. (Arrian, 104).  Diogenes Laërtius says that Nicocreon, the tyrant of Cyprus, commanded him to be pounded to death in a mortar, and that he endured this torture with fortitude. Cicero relates the same story.  Philosophy Very little is known about his philosophical views. It is thought that he represents a link between the atomism of Democritus, and the skepticism of Pyrrho.  Anaxarchus is said to have studied under Diogenes of Smyrna, whose teachings were said to be the same as those of Democritus\\' student Protagoras. Diogenes studied under Metrodorus of Chios, who used to declare that he knew nothing, not even the fact that he knew nothing. According to Sextus Empiricus, Anaxarchus \"compared existing things to a scene-painting and supposed them to resemble the impressions experienced in sleep or madness.\" Anaxarchus\\'s student Pyrrho is said to have adopted \"a most noble philosophy, … taking the form of agnosticism and suspension of judgement.\" Anaxarchus is said to have praised Pyrrho\\'s \"indifference and sang-froid.\" Anaxarchus is said to have possessed \"fortitude and contentment in life,\" which earned him the epithet eudaimonikos (\"fortunate\"), which may imply that he held the end of life to be eudaimonia.  Plutarch reports that he told Alexander the Great that there were an infinite number of worlds, leading Alexander to weep, for he had not yet conquered even one.  References  External links  4th-century BC Greek people 4th-century BC philosophers Abderites Ancient Greek atomist philosophers Ancient Thracian Greeks Hellenistic-era philosophers Philosophers and tutors of Alexander the Great Ancient Skeptic philosophers Executed philosophers Pyrrhonism',\n",
       " 'Anglo-Saxons were Germanic tribes that settled in Britain and founded England.  Anglo-Saxon may also refer to:  Anglo-Saxon (anthropology) or Nordic race, one of the putative Caucasian sub-races  Anglo-Saxon England, the history of Anglo-Saxons  Anglo-Saxon model, modern macroeconomic term  Anglo-Saxon world, modern societies based on or influenced by English customs  Old English or Anglo-Saxon, the earliest historical form of the English language  , one of various ships  White Anglo-Saxon Protestant, an ethnicity in the U.S.  See also  Anglo, a prefix  Saxon (disambiguation)',\n",
       " 'The Auger effect or Auger−Meitner effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. When a core electron is removed, leaving a vacancy, an electron from a higher energy level may fall into the vacancy, resulting in a release of energy. Although most often this energy is released in the form of an emitted photon, the energy can also be transferred to another electron, which is ejected from the atom; this second ejected electron is called an Auger electron.  Effect The effect was first discovered by Lise Meitner in 1922; Pierre Victor Auger independently discovered the effect shortly after and is credited with the discovery in most of the scientific community.  Upon ejection, the kinetic energy of the Auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the Auger electron was ejected. These energy levels depend on the type of atom and the chemical environment in which the atom was located.  Auger electron spectroscopy involves the emission of Auger electrons by bombarding a sample with either X-rays or energetic electrons and measures the intensity of Auger electrons that result as a function of the Auger electron energy. The resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment.  Auger recombination is a similar Auger effect which occurs in semiconductors. An electron and electron hole (electron-hole pair) can recombine giving up their energy to an electron in the conduction band, increasing its energy. The reverse effect is known as impact ionization.  The Auger effect can impact biological molecules such as DNA. Following the K-shell ionization of the component atoms of DNA, Auger electrons are ejected leading to damage of its sugar-phosphate backbone.  Discovery The Auger emission process was observed and published in 1922 by Lise Meitner, an Austrian-Swedish physicist, as a side effect in her competitive search for the nuclear beta electrons with the British physicist Charles Drummond Ellis.  The French physicist Pierre Victor Auger independently discovered it in 1923 upon analysis of a Wilson cloud chamber experiment and it became the central part of his PhD work. High-energy X-rays were applied to ionize gas particles and observe photoelectric electrons. The observation of electron tracks that were independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition. Further investigation, and theoretical work using elementary quantum mechanics and transition rate/transition probability calculations, showed that the effect was a radiationless effect more than an internal conversion effect.  See also Auger therapy Charge carrier generation and recombination Characteristic X-ray Coster–Kronig transition Electron capture Radiative Auger effect  References  Atomic physics Foundational quantum physics Electron spectroscopy',\n",
       " 'Ananke is the Greek goddess of fate. Ananke may also refer to:  Ananke (moon), a moon of Jupiter Ananke group, a group of satellites of Jupiter that follow similar orbits to Ananke \"Ananke\", a short story by Stanisław Lem from Tales of Pirx the Pilot Cosmopterix ananke, a moth of family Cosmopterigidae',\n",
       " \"Aeclanum (also spelled Aeculanum, , ) was an ancient town of Samnium, southern Italy, about 25\\xa0km east-southeast of Beneventum, on the Via Appia. It lies in Passo di Mirabella, near the modern Mirabella Eclano.  It is now an archaeological park.  Location   Aeclanum was on a promontory naturally defended, to some extent, by a steep slope on the south side down to the river Calore, while the north side lay open towards the crest of the ridge that where the Via Appia ran. This led through Lacus Ampsanctus to Aquilonia and Venusia. Two other routes to Apulia, the  and , diverged nearby, leading through Aequum Tuticum to Luceria and through Trivicum to Herdoniae respectively. The road from Aeclanum to Abellinum (modern Atripalda, near Avellino) may also follow an ancient line.   Today there are ruins of the city walls, of an aqueduct, baths and an amphitheatre; nearly 400 inscriptions have also been discovered. Excavation has revealed a long history of pre-Roman settlement.  History  Aeclanum was a town of the Hirpini, although it was never mentioned during the Samnite wars. Sulla captured it in 89 BC by setting on fire the wooden breastwork by which it was defended, and sacked it. It quickly recovered, new fortifications were erected, and it became a municipium. Hadrian, who repaired the Via Appia from Beneventum to this point, made it a colonia (colony).   With the Lombard invasion of Italy, in the 6th century AD, it was annexed to the Duchy of Benevento, but was captured and destroyed by Eastern Roman forces under Constans II in 663 and never recovered, being reduced to a small hamlet known as Quintodecimo, a name that referred to its distance of 15 Roman miles from Benevento.  Bishopric  Aeclanum became a Christian episcopal see, whose best known bishop was Julian of Eclanum, who was consecrated by Pope Innocent I in about 417. He refused to sign the condemnation of Pelagianism issued by Pope Innocent's successor, Pope Zosimus, and carried on a war of writings against Augustine of Hippo. It has been thought that the diocese was united to that of Frequentium as early as the 5th century, but there is mention of Quintodecimo as a suffragan see of Benevento in 969 and 1058. From 1059 it was definitively united with Frequentium. No longer a residential bishopric, Aeclanum is today listed by the Catholic Church as a titular see.  Gallery  References  External links   Aeclanum (Cultural Property of Campania website)  Aeclanum (Mirabella Eclano municipal website)  Roman sites of Campania Samnite cities Former populated places in Italy Province of Avellino Human remains (archaeological) Archaeological sites in Campania Roman towns and cities in Italy Archaeological parks Buildings and structures in Campania Tourist attractions in Campania Tourism in Italy Osci Italic archaeological sites Ruins in Italy Destroyed cities Coloniae (Roman)\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = dataset['train']['text']\n",
    "sentences = [x.replace(\"\\n\", \" \") for x in sentences]\n",
    "sentences = [x for x in sentences if len(x.split()) <= 500]\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset('bookcorpus', split='train[:1%]')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = dataset['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making vocabs\n",
    "\n",
    "Before making the vocabs, let's remove all question marks and perios, etc, then turn everything to lowercase, and then simply split the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anaxarchus (; ; ) was a greek philosopher of the school of democritus together with pyrrho he accompanied alexander the great into asia the reports of his philosophical views suggest that he was a forerunner of pyrrhonism aelian writes that he was called eudaemonicus or \"happy man\" ()  life   anaxarchus was born at abdera in thrace he was the companion and friend of alexander the great in his asiatic campaigns according to diogenes laërtius in response to alexander\\'s claim to have been the son of zeusammon anaxarchus pointed to his bleeding wound and remarked \"see the blood of a mortal not ichor such as flows from the veins of the immortal gods\" aelian writes that anaxarchus laughed at alexander for making himself a god and said \"the hopes of our god are in a porringer of broth\" when the physician prescribed a broth to alexander  plutarch tells a story that at bactra in 327\\xa0bc in a debate with callisthenes he advised all to worship alexander as a god even during his lifetime as they would surely do it after he died  when alexander was trying to show that he is divine so that the macedonians would perform proskynesis to him anaxarchus said that alexander could \"more justly be considered a god than dionysus or heracles\" as dionysus was theban while heracles was alexander\\'s nonmacedonian ancestor (arrian 104)  diogenes laërtius says that nicocreon the tyrant of cyprus commanded him to be pounded to death in a mortar and that he endured this torture with fortitude cicero relates the same story  philosophy very little is known about his philosophical views it is thought that he represents a link between the atomism of democritus and the skepticism of pyrrho  anaxarchus is said to have studied under diogenes of smyrna whose teachings were said to be the same as those of democritus\\' student protagoras diogenes studied under metrodorus of chios who used to declare that he knew nothing not even the fact that he knew nothing according to sextus empiricus anaxarchus \"compared existing things to a scenepainting and supposed them to resemble the impressions experienced in sleep or madness\" anaxarchus\\'s student pyrrho is said to have adopted \"a most noble philosophy … taking the form of agnosticism and suspension of judgement\" anaxarchus is said to have praised pyrrho\\'s \"indifference and sangfroid\" anaxarchus is said to have possessed \"fortitude and contentment in life\" which earned him the epithet eudaimonikos (\"fortunate\") which may imply that he held the end of life to be eudaimonia  plutarch reports that he told alexander the great that there were an infinite number of worlds leading alexander to weep for he had not yet conquered even one  references  external links  4thcentury bc greek people 4thcentury bc philosophers abderites ancient greek atomist philosophers ancient thracian greeks hellenisticera philosophers philosophers and tutors of alexander the great ancient skeptic philosophers executed philosophers pyrrhonism',\n",
       " 'anglosaxons were germanic tribes that settled in britain and founded england  anglosaxon may also refer to:  anglosaxon (anthropology) or nordic race one of the putative caucasian subraces  anglosaxon england the history of anglosaxons  anglosaxon model modern macroeconomic term  anglosaxon world modern societies based on or influenced by english customs  old english or anglosaxon the earliest historical form of the english language   one of various ships  white anglosaxon protestant an ethnicity in the us  see also  anglo a prefix  saxon (disambiguation)',\n",
       " 'the auger effect or auger−meitner effect is a physical phenomenon in which the filling of an innershell vacancy of an atom is accompanied by the emission of an electron from the same atom when a core electron is removed leaving a vacancy an electron from a higher energy level may fall into the vacancy resulting in a release of energy although most often this energy is released in the form of an emitted photon the energy can also be transferred to another electron which is ejected from the atom; this second ejected electron is called an auger electron  effect the effect was first discovered by lise meitner in 1922; pierre victor auger independently discovered the effect shortly after and is credited with the discovery in most of the scientific community  upon ejection the kinetic energy of the auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the auger electron was ejected these energy levels depend on the type of atom and the chemical environment in which the atom was located  auger electron spectroscopy involves the emission of auger electrons by bombarding a sample with either xrays or energetic electrons and measures the intensity of auger electrons that result as a function of the auger electron energy the resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment  auger recombination is a similar auger effect which occurs in semiconductors an electron and electron hole (electronhole pair) can recombine giving up their energy to an electron in the conduction band increasing its energy the reverse effect is known as impact ionization  the auger effect can impact biological molecules such as dna following the kshell ionization of the component atoms of dna auger electrons are ejected leading to damage of its sugarphosphate backbone  discovery the auger emission process was observed and published in 1922 by lise meitner an austrianswedish physicist as a side effect in her competitive search for the nuclear beta electrons with the british physicist charles drummond ellis  the french physicist pierre victor auger independently discovered it in 1923 upon analysis of a wilson cloud chamber experiment and it became the central part of his phd work highenergy xrays were applied to ionize gas particles and observe photoelectric electrons the observation of electron tracks that were independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition further investigation and theoretical work using elementary quantum mechanics and transition rate/transition probability calculations showed that the effect was a radiationless effect more than an internal conversion effect  see also auger therapy charge carrier generation and recombination characteristic xray coster–kronig transition electron capture radiative auger effect  references  atomic physics foundational quantum physics electron spectroscopy',\n",
       " 'ananke is the greek goddess of fate ananke may also refer to:  ananke (moon) a moon of jupiter ananke group a group of satellites of jupiter that follow similar orbits to ananke \"ananke\" a short story by stanisław lem from tales of pirx the pilot cosmopterix ananke a moth of family cosmopterigidae',\n",
       " \"aeclanum (also spelled aeculanum  ) was an ancient town of samnium southern italy about 25\\xa0km eastsoutheast of beneventum on the via appia it lies in passo di mirabella near the modern mirabella eclano  it is now an archaeological park  location   aeclanum was on a promontory naturally defended to some extent by a steep slope on the south side down to the river calore while the north side lay open towards the crest of the ridge that where the via appia ran this led through lacus ampsanctus to aquilonia and venusia two other routes to apulia the  and  diverged nearby leading through aequum tuticum to luceria and through trivicum to herdoniae respectively the road from aeclanum to abellinum (modern atripalda near avellino) may also follow an ancient line   today there are ruins of the city walls of an aqueduct baths and an amphitheatre; nearly 400 inscriptions have also been discovered excavation has revealed a long history of preroman settlement  history  aeclanum was a town of the hirpini although it was never mentioned during the samnite wars sulla captured it in 89 bc by setting on fire the wooden breastwork by which it was defended and sacked it it quickly recovered new fortifications were erected and it became a municipium hadrian who repaired the via appia from beneventum to this point made it a colonia (colony)   with the lombard invasion of italy in the 6th century ad it was annexed to the duchy of benevento but was captured and destroyed by eastern roman forces under constans ii in 663 and never recovered being reduced to a small hamlet known as quintodecimo a name that referred to its distance of 15 roman miles from benevento  bishopric  aeclanum became a christian episcopal see whose best known bishop was julian of eclanum who was consecrated by pope innocent i in about 417 he refused to sign the condemnation of pelagianism issued by pope innocent's successor pope zosimus and carried on a war of writings against augustine of hippo it has been thought that the diocese was united to that of frequentium as early as the 5th century but there is mention of quintodecimo as a suffragan see of benevento in 969 and 1058 from 1059 it was definitively united with frequentium no longer a residential bishopric aeclanum is today listed by the catholic church as a titular see  gallery  references  external links   aeclanum (cultural property of campania website)  aeclanum (mirabella eclano municipal website)  roman sites of campania samnite cities former populated places in italy province of avellino human remains (archaeological) archaeological sites in campania roman towns and cities in italy archaeological parks buildings and structures in campania tourist attractions in campania tourism in italy osci italic archaeological sites ruins in italy destroyed cities coloniae (roman)\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [x.lower() for x in sentences] #lower case\n",
    "text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating word2id: 598003it [00:00, 2254539.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "598007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Combine everything into one to make vocab\n",
    "word_list = list(set(\" \".join(text).split()))\n",
    "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}  # special tokens\n",
    "\n",
    "# Create the word2id in a single pass\n",
    "for i, w in tqdm(enumerate(word_list), desc=\"Creating word2id\"):\n",
    "    word2id[w] = i + 4  # because 0-3 are already occupied\n",
    "\n",
    "# Precompute the id2word mapping (this can be done once after word2id is fully populated)\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences:   0%|          | 0/74796 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 74796/74796 [00:02<00:00, 25284.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# List of all tokens for the whole text\n",
    "token_list = []\n",
    "\n",
    "# Process sentences more efficiently\n",
    "for sentence in tqdm(text, desc=\"Processing sentences\"):\n",
    "    token_list.append([word2id[word] for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaxarchus (; ; ) was a Greek philosopher of the school of Democritus. Together with Pyrrho, he accompanied Alexander the Great into Asia. The reports of his philosophical views suggest that he was a forerunner of Pyrrhonism. Aelian writes that he was called Eudaemonicus or \"Happy Man\" ().  Life   Anaxarchus was born at Abdera in Thrace. He was the companion and friend of Alexander the Great in his Asiatic campaigns. According to Diogenes Laërtius, in response to Alexander\\'s claim to have been the son of Zeus-Ammon, Anaxarchus pointed to his bleeding wound and remarked, \"See the blood of a mortal, not ichor, such as flows from the veins of the immortal gods.\" Aelian, writes that Anaxarchus laughed at Alexander for making himself a god and said, \"The hopes of our god are in a porringer of broth\", when the physician prescribed a broth to Alexander.  Plutarch tells a story that at Bactra, in 327\\xa0BC in a debate with Callisthenes, he advised all to worship Alexander as a god even during his lifetime, as they would surely do it after he died.  When Alexander was trying to show that he is divine so that the Macedonians would perform proskynesis to him, Anaxarchus said that Alexander could \"more justly be considered a god than Dionysus or Heracles\", as Dionysus was Theban while Heracles was Alexander\\'s non-Macedonian ancestor. (Arrian, 104).  Diogenes Laërtius says that Nicocreon, the tyrant of Cyprus, commanded him to be pounded to death in a mortar, and that he endured this torture with fortitude. Cicero relates the same story.  Philosophy Very little is known about his philosophical views. It is thought that he represents a link between the atomism of Democritus, and the skepticism of Pyrrho.  Anaxarchus is said to have studied under Diogenes of Smyrna, whose teachings were said to be the same as those of Democritus\\' student Protagoras. Diogenes studied under Metrodorus of Chios, who used to declare that he knew nothing, not even the fact that he knew nothing. According to Sextus Empiricus, Anaxarchus \"compared existing things to a scene-painting and supposed them to resemble the impressions experienced in sleep or madness.\" Anaxarchus\\'s student Pyrrho is said to have adopted \"a most noble philosophy, … taking the form of agnosticism and suspension of judgement.\" Anaxarchus is said to have praised Pyrrho\\'s \"indifference and sang-froid.\" Anaxarchus is said to have possessed \"fortitude and contentment in life,\" which earned him the epithet eudaimonikos (\"fortunate\"), which may imply that he held the end of life to be eudaimonia.  Plutarch reports that he told Alexander the Great that there were an infinite number of worlds, leading Alexander to weep, for he had not yet conquered even one.  References  External links  4th-century BC Greek people 4th-century BC philosophers Abderites Ancient Greek atomist philosophers Ancient Thracian Greeks Hellenistic-era philosophers Philosophers and tutors of Alexander the Great Ancient Skeptic philosophers Executed philosophers Pyrrhonism',\n",
       " 'Anglo-Saxons were Germanic tribes that settled in Britain and founded England.  Anglo-Saxon may also refer to:  Anglo-Saxon (anthropology) or Nordic race, one of the putative Caucasian sub-races  Anglo-Saxon England, the history of Anglo-Saxons  Anglo-Saxon model, modern macroeconomic term  Anglo-Saxon world, modern societies based on or influenced by English customs  Old English or Anglo-Saxon, the earliest historical form of the English language  , one of various ships  White Anglo-Saxon Protestant, an ethnicity in the U.S.  See also  Anglo, a prefix  Saxon (disambiguation)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at sentences\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[328282,\n",
       "  31364,\n",
       "  132416,\n",
       "  59904,\n",
       "  476163,\n",
       "  477213,\n",
       "  58507,\n",
       "  563614,\n",
       "  73354,\n",
       "  59906,\n",
       "  472397,\n",
       "  73354,\n",
       "  16106,\n",
       "  515323,\n",
       "  2060,\n",
       "  309637,\n",
       "  314573,\n",
       "  330322,\n",
       "  5639,\n",
       "  59906,\n",
       "  309546,\n",
       "  57954,\n",
       "  128633,\n",
       "  59906,\n",
       "  210758,\n",
       "  73354,\n",
       "  433651,\n",
       "  597326,\n",
       "  115270,\n",
       "  210788,\n",
       "  92999,\n",
       "  314573,\n",
       "  476163,\n",
       "  477213,\n",
       "  208762,\n",
       "  73354,\n",
       "  92230,\n",
       "  410564,\n",
       "  310797,\n",
       "  92999,\n",
       "  314573,\n",
       "  476163,\n",
       "  204475,\n",
       "  440773,\n",
       "  150909,\n",
       "  460135,\n",
       "  214728,\n",
       "  207139,\n",
       "  44260,\n",
       "  328282,\n",
       "  476163,\n",
       "  455007,\n",
       "  203528,\n",
       "  54936,\n",
       "  424106,\n",
       "  107953,\n",
       "  314573,\n",
       "  476163,\n",
       "  59906,\n",
       "  537292,\n",
       "  424141,\n",
       "  103703,\n",
       "  73354,\n",
       "  5639,\n",
       "  59906,\n",
       "  309546,\n",
       "  424106,\n",
       "  433651,\n",
       "  333685,\n",
       "  225526,\n",
       "  132982,\n",
       "  286952,\n",
       "  54303,\n",
       "  384682,\n",
       "  424106,\n",
       "  295582,\n",
       "  286952,\n",
       "  83661,\n",
       "  132199,\n",
       "  286952,\n",
       "  248288,\n",
       "  57511,\n",
       "  59906,\n",
       "  99886,\n",
       "  73354,\n",
       "  267368,\n",
       "  328282,\n",
       "  167135,\n",
       "  286952,\n",
       "  433651,\n",
       "  492374,\n",
       "  124449,\n",
       "  424141,\n",
       "  263343,\n",
       "  394819,\n",
       "  59906,\n",
       "  589872,\n",
       "  73354,\n",
       "  477213,\n",
       "  172327,\n",
       "  43030,\n",
       "  336823,\n",
       "  288853,\n",
       "  58869,\n",
       "  195030,\n",
       "  264974,\n",
       "  59906,\n",
       "  285928,\n",
       "  73354,\n",
       "  59906,\n",
       "  204797,\n",
       "  476679,\n",
       "  410564,\n",
       "  310797,\n",
       "  92999,\n",
       "  328282,\n",
       "  421666,\n",
       "  203528,\n",
       "  5639,\n",
       "  84324,\n",
       "  58188,\n",
       "  566013,\n",
       "  477213,\n",
       "  529693,\n",
       "  424141,\n",
       "  386071,\n",
       "  107493,\n",
       "  385033,\n",
       "  73354,\n",
       "  20290,\n",
       "  529693,\n",
       "  218070,\n",
       "  424106,\n",
       "  477213,\n",
       "  234803,\n",
       "  73354,\n",
       "  399925,\n",
       "  506351,\n",
       "  59906,\n",
       "  112014,\n",
       "  101762,\n",
       "  477213,\n",
       "  383637,\n",
       "  286952,\n",
       "  5639,\n",
       "  192836,\n",
       "  64420,\n",
       "  477213,\n",
       "  191263,\n",
       "  92999,\n",
       "  203528,\n",
       "  188806,\n",
       "  424106,\n",
       "  89861,\n",
       "  393154,\n",
       "  424106,\n",
       "  477213,\n",
       "  362905,\n",
       "  2060,\n",
       "  580700,\n",
       "  314573,\n",
       "  355924,\n",
       "  217064,\n",
       "  286952,\n",
       "  559375,\n",
       "  5639,\n",
       "  58869,\n",
       "  477213,\n",
       "  529693,\n",
       "  144035,\n",
       "  160452,\n",
       "  433651,\n",
       "  115277,\n",
       "  58869,\n",
       "  568372,\n",
       "  573484,\n",
       "  359736,\n",
       "  296446,\n",
       "  552187,\n",
       "  37426,\n",
       "  314573,\n",
       "  359068,\n",
       "  506351,\n",
       "  5639,\n",
       "  476163,\n",
       "  240114,\n",
       "  286952,\n",
       "  284714,\n",
       "  92999,\n",
       "  314573,\n",
       "  116645,\n",
       "  402127,\n",
       "  291752,\n",
       "  92999,\n",
       "  59906,\n",
       "  354243,\n",
       "  573484,\n",
       "  446163,\n",
       "  194031,\n",
       "  286952,\n",
       "  53262,\n",
       "  328282,\n",
       "  386071,\n",
       "  92999,\n",
       "  5639,\n",
       "  549257,\n",
       "  95436,\n",
       "  329280,\n",
       "  293903,\n",
       "  89136,\n",
       "  477213,\n",
       "  529693,\n",
       "  212452,\n",
       "  595223,\n",
       "  150909,\n",
       "  78676,\n",
       "  58869,\n",
       "  595223,\n",
       "  476163,\n",
       "  287579,\n",
       "  27694,\n",
       "  350181,\n",
       "  476163,\n",
       "  83661,\n",
       "  56251,\n",
       "  522432,\n",
       "  557952,\n",
       "  8371,\n",
       "  54303,\n",
       "  384682,\n",
       "  419274,\n",
       "  92999,\n",
       "  560116,\n",
       "  59906,\n",
       "  111719,\n",
       "  73354,\n",
       "  350225,\n",
       "  305509,\n",
       "  53262,\n",
       "  286952,\n",
       "  293903,\n",
       "  116856,\n",
       "  286952,\n",
       "  36832,\n",
       "  424106,\n",
       "  477213,\n",
       "  273603,\n",
       "  424141,\n",
       "  92999,\n",
       "  314573,\n",
       "  88711,\n",
       "  318086,\n",
       "  502541,\n",
       "  2060,\n",
       "  464655,\n",
       "  83306,\n",
       "  136434,\n",
       "  59906,\n",
       "  508752,\n",
       "  191263,\n",
       "  6356,\n",
       "  268885,\n",
       "  530981,\n",
       "  116645,\n",
       "  43404,\n",
       "  51039,\n",
       "  433651,\n",
       "  597326,\n",
       "  115270,\n",
       "  552187,\n",
       "  116645,\n",
       "  429357,\n",
       "  92999,\n",
       "  314573,\n",
       "  345621,\n",
       "  477213,\n",
       "  322940,\n",
       "  100118,\n",
       "  59906,\n",
       "  108092,\n",
       "  73354,\n",
       "  16106,\n",
       "  424141,\n",
       "  59906,\n",
       "  467404,\n",
       "  73354,\n",
       "  309637,\n",
       "  328282,\n",
       "  116645,\n",
       "  386071,\n",
       "  286952,\n",
       "  248288,\n",
       "  44573,\n",
       "  403148,\n",
       "  54303,\n",
       "  73354,\n",
       "  477477,\n",
       "  292205,\n",
       "  306843,\n",
       "  570009,\n",
       "  386071,\n",
       "  286952,\n",
       "  293903,\n",
       "  59906,\n",
       "  508752,\n",
       "  58869,\n",
       "  324551,\n",
       "  73354,\n",
       "  156973,\n",
       "  324191,\n",
       "  60847,\n",
       "  54303,\n",
       "  44573,\n",
       "  403148,\n",
       "  102396,\n",
       "  73354,\n",
       "  274267,\n",
       "  211376,\n",
       "  213114,\n",
       "  286952,\n",
       "  114478,\n",
       "  92999,\n",
       "  314573,\n",
       "  508331,\n",
       "  104884,\n",
       "  43030,\n",
       "  144035,\n",
       "  59906,\n",
       "  94375,\n",
       "  92999,\n",
       "  314573,\n",
       "  508331,\n",
       "  104884,\n",
       "  132982,\n",
       "  286952,\n",
       "  412281,\n",
       "  410764,\n",
       "  328282,\n",
       "  364851,\n",
       "  78979,\n",
       "  232317,\n",
       "  286952,\n",
       "  477213,\n",
       "  526044,\n",
       "  424141,\n",
       "  463972,\n",
       "  207405,\n",
       "  286952,\n",
       "  344620,\n",
       "  59906,\n",
       "  327533,\n",
       "  333205,\n",
       "  424106,\n",
       "  178389,\n",
       "  150909,\n",
       "  190175,\n",
       "  158455,\n",
       "  324191,\n",
       "  309637,\n",
       "  116645,\n",
       "  386071,\n",
       "  286952,\n",
       "  248288,\n",
       "  488217,\n",
       "  175828,\n",
       "  172787,\n",
       "  480079,\n",
       "  6356,\n",
       "  61649,\n",
       "  117387,\n",
       "  59906,\n",
       "  544371,\n",
       "  73354,\n",
       "  171347,\n",
       "  424141,\n",
       "  298269,\n",
       "  73354,\n",
       "  47632,\n",
       "  328282,\n",
       "  116645,\n",
       "  386071,\n",
       "  286952,\n",
       "  248288,\n",
       "  54305,\n",
       "  83874,\n",
       "  326340,\n",
       "  424141,\n",
       "  227176,\n",
       "  328282,\n",
       "  116645,\n",
       "  386071,\n",
       "  286952,\n",
       "  248288,\n",
       "  345218,\n",
       "  474899,\n",
       "  424141,\n",
       "  533378,\n",
       "  424106,\n",
       "  445609,\n",
       "  530503,\n",
       "  307393,\n",
       "  53262,\n",
       "  59906,\n",
       "  322233,\n",
       "  467531,\n",
       "  89873,\n",
       "  530503,\n",
       "  204264,\n",
       "  40528,\n",
       "  92999,\n",
       "  314573,\n",
       "  111479,\n",
       "  59906,\n",
       "  166357,\n",
       "  73354,\n",
       "  44260,\n",
       "  286952,\n",
       "  293903,\n",
       "  563179,\n",
       "  192836,\n",
       "  210758,\n",
       "  92999,\n",
       "  314573,\n",
       "  373627,\n",
       "  5639,\n",
       "  59906,\n",
       "  309546,\n",
       "  92999,\n",
       "  144537,\n",
       "  570009,\n",
       "  217195,\n",
       "  303256,\n",
       "  223745,\n",
       "  73354,\n",
       "  125564,\n",
       "  30610,\n",
       "  5639,\n",
       "  286952,\n",
       "  105092,\n",
       "  84324,\n",
       "  314573,\n",
       "  13018,\n",
       "  43030,\n",
       "  337199,\n",
       "  589070,\n",
       "  144035,\n",
       "  368233,\n",
       "  403744,\n",
       "  216028,\n",
       "  24766,\n",
       "  492291,\n",
       "  393154,\n",
       "  58507,\n",
       "  199319,\n",
       "  492291,\n",
       "  393154,\n",
       "  319002,\n",
       "  184616,\n",
       "  460278,\n",
       "  58507,\n",
       "  53635,\n",
       "  319002,\n",
       "  460278,\n",
       "  569641,\n",
       "  414452,\n",
       "  545908,\n",
       "  319002,\n",
       "  319002,\n",
       "  424141,\n",
       "  101831,\n",
       "  73354,\n",
       "  5639,\n",
       "  59906,\n",
       "  309546,\n",
       "  460278,\n",
       "  549144,\n",
       "  319002,\n",
       "  101779,\n",
       "  319002,\n",
       "  92230],\n",
       " [528486,\n",
       "  570009,\n",
       "  277226,\n",
       "  28769,\n",
       "  92999,\n",
       "  128928,\n",
       "  424106,\n",
       "  360199,\n",
       "  424141,\n",
       "  329893,\n",
       "  272831,\n",
       "  398378,\n",
       "  204264,\n",
       "  414374,\n",
       "  338035,\n",
       "  2696,\n",
       "  398378,\n",
       "  380378,\n",
       "  150909,\n",
       "  167648,\n",
       "  74455,\n",
       "  368233,\n",
       "  73354,\n",
       "  59906,\n",
       "  539358,\n",
       "  217873,\n",
       "  485946,\n",
       "  398378,\n",
       "  272831,\n",
       "  59906,\n",
       "  444392,\n",
       "  73354,\n",
       "  528486,\n",
       "  398378,\n",
       "  338349,\n",
       "  586283,\n",
       "  33030,\n",
       "  312798,\n",
       "  398378,\n",
       "  61529,\n",
       "  586283,\n",
       "  88212,\n",
       "  297166,\n",
       "  92965,\n",
       "  150909,\n",
       "  40677,\n",
       "  367333,\n",
       "  301861,\n",
       "  65378,\n",
       "  481805,\n",
       "  301861,\n",
       "  150909,\n",
       "  398378,\n",
       "  59906,\n",
       "  264794,\n",
       "  6828,\n",
       "  544371,\n",
       "  73354,\n",
       "  59906,\n",
       "  301861,\n",
       "  179497,\n",
       "  368233,\n",
       "  73354,\n",
       "  304393,\n",
       "  394080,\n",
       "  330613,\n",
       "  398378,\n",
       "  378826,\n",
       "  217195,\n",
       "  25551,\n",
       "  424106,\n",
       "  59906,\n",
       "  128487,\n",
       "  262887,\n",
       "  414374,\n",
       "  23797,\n",
       "  477213,\n",
       "  256770,\n",
       "  75412,\n",
       "  121919]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at token_list\n",
    "token_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaxarchus\n",
      "(;\n",
      ";\n",
      ")\n",
      "was\n",
      "a\n",
      "greek\n",
      "philosopher\n",
      "of\n",
      "the\n",
      "school\n",
      "of\n",
      "democritus\n",
      "together\n",
      "with\n",
      "pyrrho\n",
      "he\n",
      "accompanied\n",
      "alexander\n",
      "the\n",
      "great\n",
      "into\n",
      "asia\n",
      "the\n",
      "reports\n",
      "of\n",
      "his\n",
      "philosophical\n",
      "views\n",
      "suggest\n",
      "that\n",
      "he\n",
      "was\n",
      "a\n",
      "forerunner\n",
      "of\n",
      "pyrrhonism\n",
      "aelian\n",
      "writes\n",
      "that\n",
      "he\n",
      "was\n",
      "called\n",
      "eudaemonicus\n",
      "or\n",
      "\"happy\n",
      "man\"\n",
      "()\n",
      "life\n",
      "anaxarchus\n",
      "was\n",
      "born\n",
      "at\n",
      "abdera\n",
      "in\n",
      "thrace\n",
      "he\n",
      "was\n",
      "the\n",
      "companion\n",
      "and\n",
      "friend\n",
      "of\n",
      "alexander\n",
      "the\n",
      "great\n",
      "in\n",
      "his\n",
      "asiatic\n",
      "campaigns\n",
      "according\n",
      "to\n",
      "diogenes\n",
      "laërtius\n",
      "in\n",
      "response\n",
      "to\n",
      "alexander's\n",
      "claim\n",
      "to\n",
      "have\n",
      "been\n",
      "the\n",
      "son\n",
      "of\n",
      "zeusammon\n",
      "anaxarchus\n",
      "pointed\n",
      "to\n",
      "his\n",
      "bleeding\n",
      "wound\n",
      "and\n",
      "remarked\n",
      "\"see\n",
      "the\n",
      "blood\n",
      "of\n",
      "a\n",
      "mortal\n",
      "not\n",
      "ichor\n",
      "such\n",
      "as\n",
      "flows\n",
      "from\n",
      "the\n",
      "veins\n",
      "of\n",
      "the\n",
      "immortal\n",
      "gods\"\n",
      "aelian\n",
      "writes\n",
      "that\n",
      "anaxarchus\n",
      "laughed\n",
      "at\n",
      "alexander\n",
      "for\n",
      "making\n",
      "himself\n",
      "a\n",
      "god\n",
      "and\n",
      "said\n",
      "\"the\n",
      "hopes\n",
      "of\n",
      "our\n",
      "god\n",
      "are\n",
      "in\n",
      "a\n",
      "porringer\n",
      "of\n",
      "broth\"\n",
      "when\n",
      "the\n",
      "physician\n",
      "prescribed\n",
      "a\n",
      "broth\n",
      "to\n",
      "alexander\n",
      "plutarch\n",
      "tells\n",
      "a\n",
      "story\n",
      "that\n",
      "at\n",
      "bactra\n",
      "in\n",
      "327\n",
      "bc\n",
      "in\n",
      "a\n",
      "debate\n",
      "with\n",
      "callisthenes\n",
      "he\n",
      "advised\n",
      "all\n",
      "to\n",
      "worship\n",
      "alexander\n",
      "as\n",
      "a\n",
      "god\n",
      "even\n",
      "during\n",
      "his\n",
      "lifetime\n",
      "as\n",
      "they\n",
      "would\n",
      "surely\n",
      "do\n",
      "it\n",
      "after\n",
      "he\n",
      "died\n",
      "when\n",
      "alexander\n",
      "was\n",
      "trying\n",
      "to\n",
      "show\n",
      "that\n",
      "he\n",
      "is\n",
      "divine\n",
      "so\n",
      "that\n",
      "the\n",
      "macedonians\n",
      "would\n",
      "perform\n",
      "proskynesis\n",
      "to\n",
      "him\n",
      "anaxarchus\n",
      "said\n",
      "that\n",
      "alexander\n",
      "could\n",
      "\"more\n",
      "justly\n",
      "be\n",
      "considered\n",
      "a\n",
      "god\n",
      "than\n",
      "dionysus\n",
      "or\n",
      "heracles\"\n",
      "as\n",
      "dionysus\n",
      "was\n",
      "theban\n",
      "while\n",
      "heracles\n",
      "was\n",
      "alexander's\n",
      "nonmacedonian\n",
      "ancestor\n",
      "(arrian\n",
      "104)\n",
      "diogenes\n",
      "laërtius\n",
      "says\n",
      "that\n",
      "nicocreon\n",
      "the\n",
      "tyrant\n",
      "of\n",
      "cyprus\n",
      "commanded\n",
      "him\n",
      "to\n",
      "be\n",
      "pounded\n",
      "to\n",
      "death\n",
      "in\n",
      "a\n",
      "mortar\n",
      "and\n",
      "that\n",
      "he\n",
      "endured\n",
      "this\n",
      "torture\n",
      "with\n",
      "fortitude\n",
      "cicero\n",
      "relates\n",
      "the\n",
      "same\n",
      "story\n",
      "philosophy\n",
      "very\n",
      "little\n",
      "is\n",
      "known\n",
      "about\n",
      "his\n",
      "philosophical\n",
      "views\n",
      "it\n",
      "is\n",
      "thought\n",
      "that\n",
      "he\n",
      "represents\n",
      "a\n",
      "link\n",
      "between\n",
      "the\n",
      "atomism\n",
      "of\n",
      "democritus\n",
      "and\n",
      "the\n",
      "skepticism\n",
      "of\n",
      "pyrrho\n",
      "anaxarchus\n",
      "is\n",
      "said\n",
      "to\n",
      "have\n",
      "studied\n",
      "under\n",
      "diogenes\n",
      "of\n",
      "smyrna\n",
      "whose\n",
      "teachings\n",
      "were\n",
      "said\n",
      "to\n",
      "be\n",
      "the\n",
      "same\n",
      "as\n",
      "those\n",
      "of\n",
      "democritus'\n",
      "student\n",
      "protagoras\n",
      "diogenes\n",
      "studied\n",
      "under\n",
      "metrodorus\n",
      "of\n",
      "chios\n",
      "who\n",
      "used\n",
      "to\n",
      "declare\n",
      "that\n",
      "he\n",
      "knew\n",
      "nothing\n",
      "not\n",
      "even\n",
      "the\n",
      "fact\n",
      "that\n",
      "he\n",
      "knew\n",
      "nothing\n",
      "according\n",
      "to\n",
      "sextus\n",
      "empiricus\n",
      "anaxarchus\n",
      "\"compared\n",
      "existing\n",
      "things\n",
      "to\n",
      "a\n",
      "scenepainting\n",
      "and\n",
      "supposed\n",
      "them\n",
      "to\n",
      "resemble\n",
      "the\n",
      "impressions\n",
      "experienced\n",
      "in\n",
      "sleep\n",
      "or\n",
      "madness\"\n",
      "anaxarchus's\n",
      "student\n",
      "pyrrho\n",
      "is\n",
      "said\n",
      "to\n",
      "have\n",
      "adopted\n",
      "\"a\n",
      "most\n",
      "noble\n",
      "philosophy\n",
      "…\n",
      "taking\n",
      "the\n",
      "form\n",
      "of\n",
      "agnosticism\n",
      "and\n",
      "suspension\n",
      "of\n",
      "judgement\"\n",
      "anaxarchus\n",
      "is\n",
      "said\n",
      "to\n",
      "have\n",
      "praised\n",
      "pyrrho's\n",
      "\"indifference\n",
      "and\n",
      "sangfroid\"\n",
      "anaxarchus\n",
      "is\n",
      "said\n",
      "to\n",
      "have\n",
      "possessed\n",
      "\"fortitude\n",
      "and\n",
      "contentment\n",
      "in\n",
      "life\"\n",
      "which\n",
      "earned\n",
      "him\n",
      "the\n",
      "epithet\n",
      "eudaimonikos\n",
      "(\"fortunate\")\n",
      "which\n",
      "may\n",
      "imply\n",
      "that\n",
      "he\n",
      "held\n",
      "the\n",
      "end\n",
      "of\n",
      "life\n",
      "to\n",
      "be\n",
      "eudaimonia\n",
      "plutarch\n",
      "reports\n",
      "that\n",
      "he\n",
      "told\n",
      "alexander\n",
      "the\n",
      "great\n",
      "that\n",
      "there\n",
      "were\n",
      "an\n",
      "infinite\n",
      "number\n",
      "of\n",
      "worlds\n",
      "leading\n",
      "alexander\n",
      "to\n",
      "weep\n",
      "for\n",
      "he\n",
      "had\n",
      "not\n",
      "yet\n",
      "conquered\n",
      "even\n",
      "one\n",
      "references\n",
      "external\n",
      "links\n",
      "4thcentury\n",
      "bc\n",
      "greek\n",
      "people\n",
      "4thcentury\n",
      "bc\n",
      "philosophers\n",
      "abderites\n",
      "ancient\n",
      "greek\n",
      "atomist\n",
      "philosophers\n",
      "ancient\n",
      "thracian\n",
      "greeks\n",
      "hellenisticera\n",
      "philosophers\n",
      "philosophers\n",
      "and\n",
      "tutors\n",
      "of\n",
      "alexander\n",
      "the\n",
      "great\n",
      "ancient\n",
      "skeptic\n",
      "philosophers\n",
      "executed\n",
      "philosophers\n",
      "pyrrhonism\n"
     ]
    }
   ],
   "source": [
    "#testing one sentence\n",
    "for tokens in token_list[0]:\n",
    "    print(id2word[tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loader\n",
    "\n",
    "We gonna make dataloader.  Inside here, we need to make two types of embeddings: **token embedding** and **segment embedding**\n",
    "\n",
    "1. **Token embedding** - Given “The cat is walking. The dog is barking”, we add [CLS] and [SEP] >> “[CLS] the cat is walking [SEP] the dog is barking”. \n",
    "\n",
    "2. **Segment embedding**\n",
    "A segment embedding separates two sentences, i.e., [0 0 0 0 1 1 1 1 ]\n",
    "\n",
    "3. **Masking**\n",
    "As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. In this 15%, 80% is replaced with masks, while 10% is replaced with random tokens, and the rest 10% is left as is.  Here we specified `max_pred` \n",
    "\n",
    "4. **Padding**\n",
    "Once we mask, we will add padding. For simplicity, here we padded until some specified `max_len`. \n",
    "\n",
    "Note:  `positive` and `negative` are just simply counts to keep track of the batch size.  `positive` refers to two sentences that are really next to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3 \n",
    "max_mask   = 5  # max masked tokens when 15% exceed, it will only be max_pred\n",
    "max_len    = 1000 # maximum of length to be padded; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    half_batch_size = batch_size // 2\n",
    "    positive = negative = 0\n",
    "    while positive != half_batch_size or negative != half_batch_size:\n",
    "\n",
    "        #randomly choose two sentence\n",
    "        tokens_a_index, tokens_b_index = np.random.randint(len(sentences), size=2)\n",
    "        tokens_a, tokens_b            = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "        #1. token embedding - add CLS and SEP\n",
    "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
    "\n",
    "        #2. segment embedding - which sentence is 0 and 1\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
    "        #get all the pos excluding CLS and SEP\n",
    "        candidates_masked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]']\n",
    "                                 and token != word2id['[SEP]']]\n",
    "        np.random.shuffle(candidates_masked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        #simply loop and mask accordingly\n",
    "        for pos in candidates_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            rand_val = np.random.random()\n",
    "            if rand_val < 0.1:  #10% replace with random token\n",
    "                index = np.random.randint(4, vocab_size - 1)  # random token should not involve [PAD], [CLS], [SEP], [MASK]\n",
    "                input_ids[pos] = word2id[id2word[index]]\n",
    "            elif rand_val < 0.8:  #80 replace with [MASK]\n",
    "                input_ids[pos] = word2id['[MASK]']\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        #4. pad the sentence to the max length\n",
    "        n_pad = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        #5. pad the mask tokens to the max length\n",
    "        if max_mask > n_pred:\n",
    "            n_pad = max_mask - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        #6. check whether is positive or negative\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < half_batch_size:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = make_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1000]),\n",
       " torch.Size([2, 1000]),\n",
       " torch.Size([2, 5]),\n",
       " torch.Size([2, 5]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model\n",
    "\n",
    "Recall that BERT only uses the encoder.\n",
    "\n",
    "BERT has the following components:\n",
    "\n",
    "- Embedding layers\n",
    "- Attention Mask\n",
    "- Encoder layer\n",
    "- Multi-head attention\n",
    "- Scaled dot product attention\n",
    "- Position-wise feed-forward network\n",
    "- BERT (assembling all the components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Embedding\n",
    "\n",
    "Here we simply generate the positional embedding, and sum the token embedding, positional embedding, and segment embedding together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        #x, seg: (bs, len)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, device):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(get_attn_pad_mask(input_ids, input_ids, device).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Encoder\n",
    "\n",
    "The encoder has two main components: \n",
    "\n",
    "- Multi-head Attention\n",
    "- Position-wise feed-forward network\n",
    "\n",
    "First let's make the wrapper called `EncoderLayer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
    "        self.pos_ffn       = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the scaled dot attention, to be used inside the multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k, device):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6    # number of Encoder of Encoder Layer\n",
    "n_heads  = 8    # number of heads in Multi-Head Attention\n",
    "d_model  = 768  # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Multiheadattention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_k, device):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_k\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
    "        self.device = device\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
    "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the PoswiseFeedForwardNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
    "        super(BERT, self).__init__()\n",
    "        self.params = {'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
    "                       'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
    "                       'vocab_size': vocab_size, 'max_len': max_len}\n",
    "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "        \n",
    "        # 1. predict next sentence\n",
    "        # it will be decided by first token(CLS)\n",
    "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
    "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
    "\n",
    "        # 2. predict the masked token\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
    "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "        return logits_lm, logits_nsp\n",
    "    \n",
    "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "n_layers = 12    # number of Encoder of Encoder Layer\n",
    "n_heads  = 12    # number of heads in Multi-Head Attention\n",
    "d_model  = 768  # Embedding Size\n",
    "d_ff = d_model * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2\n",
    "\n",
    "num_epoch = 700\n",
    "model = BERT(\n",
    "    n_layers, \n",
    "    n_heads, \n",
    "    d_model, \n",
    "    d_ff, \n",
    "    d_k, \n",
    "    n_segments, \n",
    "    vocab_size, \n",
    "    max_len, \n",
    "    device\n",
    ").to(device)  # Move model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 loss = 132.776276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 101/700 [14:03<1:22:10,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 loss = 3.888227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  29%|██▊       | 201/700 [27:52<1:09:22,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 loss = 3.263463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████▎     | 301/700 [41:37<55:22,  8.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 loss = 3.452553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  57%|█████▋    | 401/700 [55:30<41:35,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400 loss = 3.065888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  72%|███████▏  | 501/700 [1:09:19<27:32,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500 loss = 3.188833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  86%|████████▌ | 601/700 [1:23:10<13:58,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600 loss = 3.055272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 700/700 [1:36:52<00:00,  8.30s/it]\n"
     ]
    }
   ],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
    "\n",
    "# Move inputs to GPU\n",
    "input_ids = input_ids.to(device)\n",
    "segment_ids = segment_ids.to(device)\n",
    "masked_tokens = masked_tokens.to(device)\n",
    "masked_pos = masked_pos.to(device)\n",
    "isNext = isNext.to(device)\n",
    "\n",
    "# Wrap the epoch loop with tqdm\n",
    "for epoch in tqdm(range(num_epoch), desc=\"Training Epochs\"):\n",
    "    optimizer.zero_grad()\n",
    "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)    \n",
    "    #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
    "    #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
    "\n",
    "    #1. mlm loss\n",
    "    #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
    "    loss_lm = (loss_lm.float()).mean()\n",
    "    #2. nsp loss\n",
    "    #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
    "    loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
    "    \n",
    "    #3. combine loss\n",
    "    loss = loss_lm + loss_nsp\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch:', '%02d' % (epoch), 'loss =', '{:.6f}'.format(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_bert.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model after training\n",
    "torch.save([model.params, model.state_dict()], 'model/model_bert.pth')\n",
    "print(\"Model saved to model_bert.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference\n",
    "\n",
    "Since our dataset is very small, it won't work very well, but just for the sake of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model and all its hyperparameters\n",
    "params, state = torch.load('model/model_bert.pth')\n",
    "model_bert = BERT(**params, device=device).to(device)\n",
    "model_bert.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1,\n",
       "   416144,\n",
       "   63440,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   90369,\n",
       "   150909,\n",
       "   582273,\n",
       "   59904,\n",
       "   116645,\n",
       "   477213,\n",
       "   327895,\n",
       "   63440,\n",
       "   517581,\n",
       "   424106,\n",
       "   416144,\n",
       "   43606,\n",
       "   552187,\n",
       "   116645,\n",
       "   487361,\n",
       "   82065,\n",
       "   367333,\n",
       "   59906,\n",
       "   366721,\n",
       "   73354,\n",
       "   321807,\n",
       "   366721,\n",
       "   73354,\n",
       "   424008,\n",
       "   424141,\n",
       "   316506,\n",
       "   171086,\n",
       "   284423,\n",
       "   36366,\n",
       "   528650,\n",
       "   424141,\n",
       "   5979,\n",
       "   461576,\n",
       "   409019,\n",
       "   403148,\n",
       "   59906,\n",
       "   199817,\n",
       "   286785,\n",
       "   426125,\n",
       "   63440,\n",
       "   357938,\n",
       "   59906,\n",
       "   583138,\n",
       "   547272,\n",
       "   73354,\n",
       "   61529,\n",
       "   273526,\n",
       "   328517,\n",
       "   478877,\n",
       "   428683,\n",
       "   171878,\n",
       "   424141,\n",
       "   438972,\n",
       "   537995,\n",
       "   84324,\n",
       "   377890,\n",
       "   160702,\n",
       "   286952,\n",
       "   550615,\n",
       "   63440,\n",
       "   424141,\n",
       "   93066,\n",
       "   63440,\n",
       "   424106,\n",
       "   59906,\n",
       "   60564,\n",
       "   153975,\n",
       "   424141,\n",
       "   57651,\n",
       "   343551,\n",
       "   136842,\n",
       "   63440,\n",
       "   424106,\n",
       "   59906,\n",
       "   60564,\n",
       "   324572,\n",
       "   59906,\n",
       "   63440,\n",
       "   576831,\n",
       "   576204,\n",
       "   424106,\n",
       "   59906,\n",
       "   345747,\n",
       "   73354,\n",
       "   18136,\n",
       "   340698,\n",
       "   424141,\n",
       "   347520,\n",
       "   424106,\n",
       "   150242,\n",
       "   340698,\n",
       "   81054,\n",
       "   61529,\n",
       "   273526,\n",
       "   444392,\n",
       "   466021,\n",
       "   424106,\n",
       "   252389,\n",
       "   59906,\n",
       "   444392,\n",
       "   73354,\n",
       "   416144,\n",
       "   63440,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   145535,\n",
       "   293903,\n",
       "   580198,\n",
       "   286952,\n",
       "   59906,\n",
       "   466736,\n",
       "   426125,\n",
       "   84324,\n",
       "   59906,\n",
       "   405893,\n",
       "   73354,\n",
       "   59906,\n",
       "   348617,\n",
       "   593585,\n",
       "   213144,\n",
       "   160452,\n",
       "   59906,\n",
       "   431669,\n",
       "   424106,\n",
       "   354312,\n",
       "   347819,\n",
       "   552187,\n",
       "   332974,\n",
       "   477213,\n",
       "   563508,\n",
       "   73354,\n",
       "   239232,\n",
       "   424141,\n",
       "   117158,\n",
       "   515038,\n",
       "   497556,\n",
       "   59906,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   466736,\n",
       "   468517,\n",
       "   73354,\n",
       "   232649,\n",
       "   63440,\n",
       "   220726,\n",
       "   424141,\n",
       "   59906,\n",
       "   232649,\n",
       "   593585,\n",
       "   472397,\n",
       "   533201,\n",
       "   312018,\n",
       "   385632,\n",
       "   311507,\n",
       "   73354,\n",
       "   59906,\n",
       "   431669,\n",
       "   348617,\n",
       "   593585,\n",
       "   379447,\n",
       "   557964,\n",
       "   135478,\n",
       "   223591,\n",
       "   58869,\n",
       "   59906,\n",
       "   503019,\n",
       "   3,\n",
       "   73354,\n",
       "   59906,\n",
       "   466736,\n",
       "   426125,\n",
       "   424141,\n",
       "   59906,\n",
       "   382404,\n",
       "   73354,\n",
       "   59906,\n",
       "   472397,\n",
       "   424106,\n",
       "   59162,\n",
       "   160452,\n",
       "   59906,\n",
       "   223521,\n",
       "   264974,\n",
       "   354312,\n",
       "   286952,\n",
       "   480696,\n",
       "   424106,\n",
       "   194333,\n",
       "   59906,\n",
       "   472397,\n",
       "   476163,\n",
       "   204059,\n",
       "   3,\n",
       "   59906,\n",
       "   247875,\n",
       "   43606,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   472397,\n",
       "   203528,\n",
       "   248094,\n",
       "   574106,\n",
       "   204475,\n",
       "   574498,\n",
       "   201173,\n",
       "   286952,\n",
       "   59906,\n",
       "   247875,\n",
       "   43606,\n",
       "   348617,\n",
       "   379447,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   552187,\n",
       "   557964,\n",
       "   267538,\n",
       "   264974,\n",
       "   563544,\n",
       "   232649,\n",
       "   286952,\n",
       "   416144,\n",
       "   5979,\n",
       "   424106,\n",
       "   84698,\n",
       "   126020,\n",
       "   264974,\n",
       "   354312,\n",
       "   286952,\n",
       "   126020,\n",
       "   485179,\n",
       "   59906,\n",
       "   239502,\n",
       "   73354,\n",
       "   67816,\n",
       "   552187,\n",
       "   451318,\n",
       "   529448,\n",
       "   503574,\n",
       "   424106,\n",
       "   59906,\n",
       "   337451,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   84324,\n",
       "   59906,\n",
       "   457289,\n",
       "   431994,\n",
       "   424106,\n",
       "   352630,\n",
       "   527841,\n",
       "   552187,\n",
       "   476163,\n",
       "   74981,\n",
       "   305076,\n",
       "   57954,\n",
       "   416144,\n",
       "   472397,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   403148,\n",
       "   59906,\n",
       "   517749,\n",
       "   202625,\n",
       "   73354,\n",
       "   59906,\n",
       "   366721,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   247875,\n",
       "   43606,\n",
       "   472397,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   416144,\n",
       "   283900,\n",
       "   3,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   424141,\n",
       "   416144,\n",
       "   63440,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   37426,\n",
       "   59906,\n",
       "   181150,\n",
       "   73354,\n",
       "   59906,\n",
       "   24422,\n",
       "   514289,\n",
       "   73354,\n",
       "   270423,\n",
       "   273526,\n",
       "   424106,\n",
       "   488561,\n",
       "   73354,\n",
       "   230396,\n",
       "   416144,\n",
       "   63440,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   240957,\n",
       "   286952,\n",
       "   293903,\n",
       "   487361,\n",
       "   280421,\n",
       "   367333,\n",
       "   393791,\n",
       "   59906,\n",
       "   479049,\n",
       "   424141,\n",
       "   59906,\n",
       "   461576,\n",
       "   409019,\n",
       "   2060,\n",
       "   59906,\n",
       "   461576,\n",
       "   409019,\n",
       "   2630,\n",
       "   59906,\n",
       "   487253,\n",
       "   189758,\n",
       "   424106,\n",
       "   259731,\n",
       "   493053,\n",
       "   59906,\n",
       "   63440,\n",
       "   548522,\n",
       "   2060,\n",
       "   59906,\n",
       "   416144,\n",
       "   124070,\n",
       "   84324,\n",
       "   65324,\n",
       "   483889,\n",
       "   538755,\n",
       "   442988,\n",
       "   116952,\n",
       "   424141,\n",
       "   36073,\n",
       "   416144,\n",
       "   63440,\n",
       "   73354,\n",
       "   107460,\n",
       "   424141,\n",
       "   18136,\n",
       "   354416,\n",
       "   73354,\n",
       "   506942,\n",
       "   116952,\n",
       "   424141,\n",
       "   36073,\n",
       "   478136,\n",
       "   472397,\n",
       "   73354,\n",
       "   565237,\n",
       "   424141,\n",
       "   316506,\n",
       "   340698,\n",
       "   472397,\n",
       "   73354,\n",
       "   424204,\n",
       "   108247,\n",
       "   576338,\n",
       "   73354,\n",
       "   424226,\n",
       "   472397,\n",
       "   73354,\n",
       "   492268,\n",
       "   366101,\n",
       "   287332,\n",
       "   490591,\n",
       "   472397,\n",
       "   73354,\n",
       "   316506,\n",
       "   209959,\n",
       "   472397,\n",
       "   73354,\n",
       "   568799,\n",
       "   472397,\n",
       "   73354,\n",
       "   488546,\n",
       "   366101,\n",
       "   287332,\n",
       "   340698,\n",
       "   472397,\n",
       "   73354,\n",
       "   37026,\n",
       "   259504,\n",
       "   472397,\n",
       "   73354,\n",
       "   426063,\n",
       "   424141,\n",
       "   347572,\n",
       "   316506,\n",
       "   472397,\n",
       "   73354,\n",
       "   34548,\n",
       "   424141,\n",
       "   505551,\n",
       "   472397,\n",
       "   73354,\n",
       "   169059,\n",
       "   424141,\n",
       "   483889,\n",
       "   472397,\n",
       "   73354,\n",
       "   584682,\n",
       "   424141,\n",
       "   307648,\n",
       "   366101,\n",
       "   472397,\n",
       "   73354,\n",
       "   423654,\n",
       "   540939,\n",
       "   472397,\n",
       "   73354,\n",
       "   558927,\n",
       "   321807,\n",
       "   468517,\n",
       "   73354,\n",
       "   411379,\n",
       "   321807,\n",
       "   472397,\n",
       "   73354,\n",
       "   25760,\n",
       "   321807,\n",
       "   240365,\n",
       "   73354,\n",
       "   5550,\n",
       "   510402,\n",
       "   558763,\n",
       "   478877,\n",
       "   116645,\n",
       "   477213,\n",
       "   30610,\n",
       "   481832,\n",
       "   424106,\n",
       "   477213,\n",
       "   7514,\n",
       "   73354,\n",
       "   340698,\n",
       "   173236,\n",
       "   58869,\n",
       "   3,\n",
       "   246015,\n",
       "   490782,\n",
       "   424141,\n",
       "   11358,\n",
       "   570801,\n",
       "   501575,\n",
       "   270423,\n",
       "   113699,\n",
       "   481644,\n",
       "   214565,\n",
       "   424106,\n",
       "   511749,\n",
       "   367333,\n",
       "   509587,\n",
       "   547272,\n",
       "   403744,\n",
       "   518821,\n",
       "   273526,\n",
       "   424141,\n",
       "   362606,\n",
       "   424106,\n",
       "   416144,\n",
       "   565237,\n",
       "   321807,\n",
       "   2,\n",
       "   89750,\n",
       "   207139,\n",
       "   116645,\n",
       "   477213,\n",
       "   117560,\n",
       "   222094,\n",
       "   424106,\n",
       "   59906,\n",
       "   245035,\n",
       "   468517,\n",
       "   424106,\n",
       "   35898,\n",
       "   424106,\n",
       "   104117,\n",
       "   521552,\n",
       "   92965,\n",
       "   594605,\n",
       "   104326,\n",
       "   227998,\n",
       "   552187,\n",
       "   476163,\n",
       "   548522,\n",
       "   57954,\n",
       "   59906,\n",
       "   51301,\n",
       "   222094,\n",
       "   242071,\n",
       "   65324,\n",
       "   262887,\n",
       "   414374,\n",
       "   519191,\n",
       "   73354,\n",
       "   59906,\n",
       "   245035,\n",
       "   468517,\n",
       "   403744,\n",
       "   117560,\n",
       "   519191,\n",
       "   73354,\n",
       "   245035,\n",
       "   538674,\n",
       "   508158,\n",
       "   504170,\n",
       "   26329,\n",
       "   424106,\n",
       "   227998,\n",
       "   227998,\n",
       "   570675,\n",
       "   424106,\n",
       "   521552,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [73354, 415629, 337281, 146325, 18136],\n",
       "  [296, 202, 176, 253, 470],\n",
       "  False],\n",
       " [[1,\n",
       "   321073,\n",
       "   251432,\n",
       "   314049,\n",
       "   398471,\n",
       "   409172,\n",
       "   401973,\n",
       "   116645,\n",
       "   217195,\n",
       "   441564,\n",
       "   435985,\n",
       "   538944,\n",
       "   211376,\n",
       "   387881,\n",
       "   385315,\n",
       "   84324,\n",
       "   226007,\n",
       "   430871,\n",
       "   424106,\n",
       "   59906,\n",
       "   255696,\n",
       "   575122,\n",
       "   368233,\n",
       "   577410,\n",
       "   5888,\n",
       "   251432,\n",
       "   533114,\n",
       "   290689,\n",
       "   472397,\n",
       "   435985,\n",
       "   203528,\n",
       "   550953,\n",
       "   290689,\n",
       "   472397,\n",
       "   424141,\n",
       "   48794,\n",
       "   435985,\n",
       "   84324,\n",
       "   320699,\n",
       "   189602,\n",
       "   132825,\n",
       "   500260,\n",
       "   211376,\n",
       "   314573,\n",
       "   552160,\n",
       "   286952,\n",
       "   128487,\n",
       "   5888,\n",
       "   435985,\n",
       "   270423,\n",
       "   379132,\n",
       "   424106,\n",
       "   393791,\n",
       "   493053,\n",
       "   424141,\n",
       "   585693,\n",
       "   124070,\n",
       "   424106,\n",
       "   486720,\n",
       "   251432,\n",
       "   401772,\n",
       "   271139,\n",
       "   106346,\n",
       "   284423,\n",
       "   63440,\n",
       "   286952,\n",
       "   578620,\n",
       "   124070,\n",
       "   435985,\n",
       "   424106,\n",
       "   335790,\n",
       "   128349,\n",
       "   2060,\n",
       "   59906,\n",
       "   236789,\n",
       "   251432,\n",
       "   382494,\n",
       "   417280,\n",
       "   399789,\n",
       "   40264,\n",
       "   477213,\n",
       "   524383,\n",
       "   586823,\n",
       "   424141,\n",
       "   70400,\n",
       "   520641,\n",
       "   335070,\n",
       "   424106,\n",
       "   104326,\n",
       "   233643,\n",
       "   251432,\n",
       "   337300,\n",
       "   314573,\n",
       "   573484,\n",
       "   115836,\n",
       "   124070,\n",
       "   25015,\n",
       "   286952,\n",
       "   521969,\n",
       "   477213,\n",
       "   409339,\n",
       "   577410,\n",
       "   409339,\n",
       "   424106,\n",
       "   488561,\n",
       "   233643,\n",
       "   251432,\n",
       "   433159,\n",
       "   84324,\n",
       "   255696,\n",
       "   254391,\n",
       "   189602,\n",
       "   499101,\n",
       "   511090,\n",
       "   520641,\n",
       "   314573,\n",
       "   110977,\n",
       "   59906,\n",
       "   48794,\n",
       "   37426,\n",
       "   477213,\n",
       "   524383,\n",
       "   471121,\n",
       "   379203,\n",
       "   58188,\n",
       "   477213,\n",
       "   286785,\n",
       "   507005,\n",
       "   336419,\n",
       "   264974,\n",
       "   488561,\n",
       "   286952,\n",
       "   352531,\n",
       "   511749,\n",
       "   251432,\n",
       "   533114,\n",
       "   575445,\n",
       "   2060,\n",
       "   236267,\n",
       "   189602,\n",
       "   160363,\n",
       "   234511,\n",
       "   440255,\n",
       "   314573,\n",
       "   161779,\n",
       "   59906,\n",
       "   236267,\n",
       "   103285,\n",
       "   472088,\n",
       "   2060,\n",
       "   71898,\n",
       "   189180,\n",
       "   424141,\n",
       "   261458,\n",
       "   335070,\n",
       "   424106,\n",
       "   82314,\n",
       "   453154,\n",
       "   171897,\n",
       "   424106,\n",
       "   59906,\n",
       "   560469,\n",
       "   424141,\n",
       "   424106,\n",
       "   25015,\n",
       "   239511,\n",
       "   251432,\n",
       "   465343,\n",
       "   84324,\n",
       "   138197,\n",
       "   189602,\n",
       "   234511,\n",
       "   440255,\n",
       "   181756,\n",
       "   58188,\n",
       "   578699,\n",
       "   399789,\n",
       "   92965,\n",
       "   385466,\n",
       "   165676,\n",
       "   377890,\n",
       "   251432,\n",
       "   381741,\n",
       "   255696,\n",
       "   575122,\n",
       "   368233,\n",
       "   189602,\n",
       "   35250,\n",
       "   430871,\n",
       "   314573,\n",
       "   382494,\n",
       "   433651,\n",
       "   72700,\n",
       "   59906,\n",
       "   98307,\n",
       "   520329,\n",
       "   206644,\n",
       "   424106,\n",
       "   477213,\n",
       "   451479,\n",
       "   549625,\n",
       "   286952,\n",
       "   51301,\n",
       "   272831,\n",
       "   464289,\n",
       "   85607,\n",
       "   403744,\n",
       "   342433,\n",
       "   65761,\n",
       "   441564,\n",
       "   435985,\n",
       "   372525,\n",
       "   276732,\n",
       "   284735,\n",
       "   181960,\n",
       "   537945,\n",
       "   134368,\n",
       "   236789,\n",
       "   78847,\n",
       "   435985,\n",
       "   372525,\n",
       "   35250,\n",
       "   430871,\n",
       "   81130,\n",
       "   372525,\n",
       "   436909,\n",
       "   199319,\n",
       "   270423,\n",
       "   555249,\n",
       "   435985,\n",
       "   276732,\n",
       "   372525,\n",
       "   270423,\n",
       "   327509,\n",
       "   435985,\n",
       "   575122,\n",
       "   372525,\n",
       "   199319,\n",
       "   264974,\n",
       "   234511,\n",
       "   440255,\n",
       "   499101,\n",
       "   511090,\n",
       "   520641,\n",
       "   372525,\n",
       "   435985,\n",
       "   372525,\n",
       "   264974,\n",
       "   234511,\n",
       "   440255,\n",
       "   60564,\n",
       "   153975,\n",
       "   78847,\n",
       "   5888,\n",
       "   354285,\n",
       "   435985,\n",
       "   372525,\n",
       "   255696,\n",
       "   575122,\n",
       "   368233,\n",
       "   372525,\n",
       "   2,\n",
       "   308152,\n",
       "   69545,\n",
       "   314049,\n",
       "   384047,\n",
       "   427485,\n",
       "   38204,\n",
       "   565333,\n",
       "   73354,\n",
       "   36832,\n",
       "   342734,\n",
       "   43404,\n",
       "   58869,\n",
       "   19094,\n",
       "   476163,\n",
       "   477213,\n",
       "   96582,\n",
       "   595748,\n",
       "   314573,\n",
       "   533114,\n",
       "   424106,\n",
       "   382983,\n",
       "   108499,\n",
       "   84324,\n",
       "   59906,\n",
       "   455838,\n",
       "   270423,\n",
       "   284735,\n",
       "   507005,\n",
       "   424106,\n",
       "   471226,\n",
       "   314573,\n",
       "   476163,\n",
       "   414374,\n",
       "   437212,\n",
       "   73354,\n",
       "   44452,\n",
       "   47998,\n",
       "   84324,\n",
       "   59906,\n",
       "   471226,\n",
       "   249573,\n",
       "   441564,\n",
       "   254391,\n",
       "   403744,\n",
       "   216028,\n",
       "   24766,\n",
       "   3,\n",
       "   65761,\n",
       "   560469,\n",
       "   73354,\n",
       "   36832,\n",
       "   360462,\n",
       "   96582,\n",
       "   281166,\n",
       "   455838,\n",
       "   354285,\n",
       "   281166,\n",
       "   394919,\n",
       "   73354,\n",
       "   504550,\n",
       "   360462,\n",
       "   276732,\n",
       "   281166,\n",
       "   43030,\n",
       "   74834,\n",
       "   367333,\n",
       "   208886,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [271139, 59906, 236789, 35250, 38204],\n",
       "  [61, 300, 74, 16, 308],\n",
       "  True]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape of batch\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'christian', 'enriquez', '(born', 'october', '25', '1998)', 'is', 'an', 'american', 'soccer', 'player', 'who', 'currently', 'plays', 'for', '(1996–1999', 'madison', 'in', 'the', 'usl', 'league', 'one', 'career', 'youth', 'enriquez', 'played', 'high', 'school', 'soccer', 'at', 'helix', 'high', 'school', 'and', 'club', 'soccer', 'for', 'ussda', 'side', 'nomads', 'sc', 'who', 'he', 'helped', 'to', 'us', 'youth', 'soccer', 'national', 'championships', 'in', 'both', '2013', 'and', '2014', 'college', 'in', '2016', 'enriquez', 'attended', 'california', 'polytechnic', 'state', 'university', 'to', 'play', 'college', 'soccer', 'in', 'two', 'seasons', 'with', 'the', 'mustangs', 'enriquez', 'made', '33', 'appearances', 'scoring', 'a', 'single', 'goal', 'and', 'tallying', '2', 'assists', 'in', 'january', '2018', 'enriquez', 'announced', 'he', 'would', 'leave', 'college', 'early', 'to', 'pursue', 'a', 'professional', 'career', 'professional', 'in', 'february', '2018', 'enriquez', 'signed', 'for', 'usl', 'championship', 'side', 'portland', 'timbers', '2', 'he', 'left', 'the', 'club', 'after', 'a', 'single', 'season', 'without', 'making', 'a', 'first', 'team', 'appearance', 'from', 'february', 'to', 'july', '2019', 'enriquez', 'played', 'semiprofessionally', 'with', 'npsl', 'side', 'asc', 'san', 'diego', 'he', 'won', 'the', 'npsl', 'golden', 'ball', 'with', 'seven', 'goals', 'and', 'six', 'assists', 'in', '19', 'games', 'later', 'in', 'the', 'year', 'and', 'in', 'early', '2020', 'enriquez', 'appeared', 'for', 'nisa', 'side', 'san', 'diego', '1904', 'making', '8', 'appearances', 'on', 'june', '18', '2021', 'enriquez', 'joined', 'usl', 'league', 'one', 'side', 'forward', 'madison', 'he', 'made', 'his', 'debut', 'the', 'following', 'day', 'starting', 'in', 'a', '2–0', 'loss', 'to', 'new', 'england', 'revolution', 'ii', 'references', '1998', 'births', 'american', 'soccer', 'players', 'association', 'football', 'midfielders', 'cal', 'poly', 'mustangs', \"men's\", 'soccer', 'players', 'forward', 'madison', 'fc', 'players', 'living', 'people', 'national', 'independent', 'soccer', 'association', 'players', 'national', 'premier', 'soccer', 'league', 'players', 'people', 'from', 'san', 'diego', 'portland', 'timbers', '2', 'players', 'soccer', 'players', 'from', 'san', 'diego', 'united', 'states', \"men's\", 'youth', 'international', 'soccer', 'players', 'usl', 'league', 'one', 'players', '[SEP]', 'orlando', 'moreira', '(born', '30', 'november', '1899', 'date', 'of', 'death', 'unknown)', 'known', 'as', 'orlandinho', 'was', 'a', 'brazilian', 'footballer', 'he', 'played', 'in', 'three', 'matches', 'for', 'the', 'brazil', 'national', 'football', 'team', 'in', '1921', 'he', 'was', 'also', 'part', 'of', \"brazil's\", 'squad', 'for', 'the', '1921', 'south', 'american', 'championship', 'references', 'external', 'links', '[MASK]', 'births', 'year', 'of', 'death', 'missing', 'brazilian', 'footballers', 'brazil', 'international', 'footballers', 'place', 'of', 'birth', 'missing', 'association', 'footballers', 'not', 'categorized', 'by', 'position', '[SEP]']\n",
      "masked tokens (words) :  ['california', 'the', 'mustangs', 'forward', '1899']\n",
      "masked tokens list :  [271139, 59906, 236789, 35250, 38204]\n",
      "masked tokens (words) :  ['teacher', 'teacher', 'teacher', 'teacher', 'teacher']\n",
      "predict masked tokens list :  [337281, 337281, 337281, 337281, 337281]\n",
      "0\n",
      "isNext :  True\n",
      "predict isNext :  False\n"
     ]
    }
   ],
   "source": [
    "# Predict mask tokens ans isNext\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[1]))\n",
    "print([id2word[w.item()] for w in input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
    "input_ids = input_ids.to(device)\n",
    "segment_ids = segment_ids.to(device)\n",
    "masked_tokens = masked_tokens.to(device)\n",
    "masked_pos = masked_pos.to(device)\n",
    "isNext = isNext.to(device)\n",
    "\n",
    "logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
    "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
    "\n",
    "#predict masked tokens\n",
    "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
    "logits_lm = logits_lm.data.cpu().max(2)[1][0].data.numpy() \n",
    "#note that zero is padding we add to the masked_tokens\n",
    "print('masked tokens (words) : ',[id2word[pos.item()] for pos in masked_tokens[0]])\n",
    "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0]])\n",
    "print('masked tokens (words) : ',[id2word[pos.item()] for pos in logits_lm])\n",
    "print('predict masked tokens list : ', [pos for pos in logits_lm])\n",
    "\n",
    "#predict nsp\n",
    "logits_nsp = logits_nsp.cpu().data.max(1)[1][0].data.numpy()\n",
    "print(logits_nsp)\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_nsp else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Task-2` and `Task-3` are carried out in a seperate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
